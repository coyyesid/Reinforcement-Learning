{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tarea 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Punto 1:_\n",
    "\n",
    "### 1. Modelado del problema como un MDP\n",
    "\n",
    "Modele este problema como un MDP. Detalle todos los elementos del MDP:\n",
    "\n",
    "- **Estados**  \n",
    "- **Recompensas**  \n",
    "- **Acciones**  \n",
    "- **DinÃ¡mica de transiciÃ³n**:  \n",
    "  $$ p(s', r \\mid s, a) \\quad \\forall s, s', r, a $$  \n",
    "- **Factor de descuento**:  \n",
    "  $$ \\gamma $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen los elementos del MDP, estableciendo 100 estados que representan las casillas numeradas del tablero. Cada estado corresponde a una casilla especÃ­fica, desde la 1 hasta la 100. AdemÃ¡s, se definen dos acciones posibles: avanzar (+1) o retroceder (âˆ’1), lo que significa que el jugador puede decidir moverse hacia adelante o hacia atrÃ¡s. Esto permite parametrizar el sentido del movimiento, ya que permite al jugador evitar caer en serpientes o posicionarse mejor para subir por una escalera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el nÃºmero de estados y acciones\n",
    "numEstados = 100  # Casillas del tablero\n",
    "acciones = [-1, 1]  # -1: Retroceder, 1: Avanzar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen las razones de probabilidad del dado cargado, lo que significa que las probailidades no son uniformes, algunas tienen mÃ¡s probabilidad de salir que otras. En lugar de un dado justo con una probabilidad uniforme de 1/6, aquÃ­ se asignan valores especÃ­ficos: sacar un 1 o 6 tiene una probabilidad de 10%, un 2 o un 5 ocurre el 15% del tiempo, y un 3 o un 4 sucede con mayor frecuencia (20%). Esto afecta las transiciones del MDP, ya que los valores medios (3 y 4) serÃ¡n mÃ¡s comunes, influyendo en la estrategia Ã³ptima del jugador al moverse en el tablero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades = [0.125, 0.175, 0.2, 0.2, 0.175, 0.125]  # Probabilidades del dado cargado acuerdo distribuciÃ³n normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaciÃ³n, se definen dos diccionarios en Python que modelan las escaleras y serpientes del tablero, donde las claves representan las casillas de inicio y los valores indican las casillas destino. El diccionario escaleras indica las casillas donde un jugador avanza automÃ¡ticamente a una posiciÃ³n mÃ¡s alta, mientras que serpientes representa las casillas que obligan al jugador a retroceder, dificultando su progreso. Estas transiciones no lineales afectan la dinÃ¡mica del juego y se incorporan en la funciÃ³n de probabilidad de transiciÃ³n del MDP, asegurando que el modelo refleje correctamente las reglas del juego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir posiciones de escaleras y serpientes\n",
    "escaleras = {8: 26, 21: 82, 43: 77, 50: 91, 54: 93, 66: 87, 62: 96, 80: 100} # modelado de 8 escaleras\n",
    "serpientes = {52: 11, 69: 33, 92: 51, 48: 9, 73: 1, 55: 7, 46: 5, 95: 24, 64: 36, 44: 22, 98: 28, 83: 19, 59: 17} # modelado de serpientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen mediante listas, los estados correspondientes a victoria o derrota denotados en la grafica de color azul y rojo respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casillas de victoria y derrota\n",
    "estadoGanar = [80, 100]  # Casillas azules\n",
    "estadoPerder = [23, 37, 45, 67, 89]  # Casillas rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se modela la variable gamma que en el MDP permite dar relevancia a la evoluciÃ³n de los estados en el tiempo, el valor de 0.9 se parametriza para dar mayor relevancia a los estados recientes en comparaciÃ³n a los estados mÃ¡s antiguos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor de descuento\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se modela una funciÃ³n que modela las probabbilidades de transiciÃ³n en el talero de juego, esta calcula la distribuciÃ³n de probabilidad de transiciÃ³n en el tablero de escaleras y serpientes, modelando cÃ³mo un jugador se moverÃ¡ desde un estado actual ð‘  tras tomar una acciÃ³n ð‘Ž y lanzar el dado. Para cada posible resultado del dado, ajusta el estado futuro sumando o restando el valor obtenido segÃºn la acciÃ³n tomada. Luego, maneja los rebotes en los extremos del tablero si el jugador supera la casilla 100 o cae por debajo de la casilla 1. Posteriormente, aplica las reglas de escaleras y serpientes, trasladando al jugador si cae en una de estas casillas. Finalmente, almacena la probabilidad acumulada de alcanzar cada estado en un vector, asegurando que la suma total de probabilidades sea 1, y lo retorna, permitiendo definir la matriz de transiciÃ³n ð‘ƒ(ð‘ â€²âˆ£ð‘ ,ð‘Ž) clave en el MDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probTransicion(s, a, probabilidades):\n",
    "    \"\"\" Calcula la distribuciÃ³n de probabilidad para el prÃ³ximo estado.\"\"\"\n",
    "    prob_nuevoEstado = np.zeros(numEstados + 1)  # De 1 a 100\n",
    "    \n",
    "    for lanzamiento, prob in enumerate(probabilidades, start=1):\n",
    "        nuevoEstado = s + a * lanzamiento\n",
    "        \n",
    "        # Rebote en los extremos\n",
    "        if nuevoEstado > 100:\n",
    "            nuevoEstado = 100 - (nuevoEstado - 100)\n",
    "        elif nuevoEstado < 1:\n",
    "            nuevoEstado = 1 + (1 - nuevoEstado)\n",
    "        \n",
    "        # Escaleras y serpientes\n",
    "        if nuevoEstado in escaleras:\n",
    "            nuevoEstado = escaleras[nuevoEstado]\n",
    "        elif nuevoEstado in serpientes:\n",
    "            nuevoEstado = serpientes[nuevoEstado]\n",
    "        \n",
    "        prob_nuevoEstado[nuevoEstado] += prob\n",
    "    \n",
    "    return prob_nuevoEstado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se modela la funciÃ³n de recomensas, esta asigna una recompensa a cada estado ð‘  segÃºn su impacto en el juego, retornando +1 si el jugador alcanza una casilla de victoria (estadoGanar), -1 si cae en una casilla de derrota (estadoPerder), y -0.01 en cualquier otro caso como penalizaciÃ³n por movimiento, incentivando asÃ­ estrategias que minimicen el nÃºmero de pasos y maximicen la recompensa total en el MDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funRecompensa(s):\n",
    "    \"\"\" Define la funciÃ³n de recompensa.\"\"\"\n",
    "    if s in estadoGanar:\n",
    "        return 1  # Victoria\n",
    "    elif s in estadoPerder:\n",
    "        return -1  # Derrota\n",
    "    return -0.01  # PenalizaciÃ³n por movimiento\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
