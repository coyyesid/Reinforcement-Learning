{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tarea 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Punto 1:_\n",
    "\n",
    "### 1. Modelado del problema como un MDP\n",
    "\n",
    "Modele este problema como un MDP. Detalle todos los elementos del MDP:\n",
    "\n",
    "- **Estados**  \n",
    "- **Recompensas**  \n",
    "- **Acciones**  \n",
    "- **Din谩mica de transici贸n**:  \n",
    "  $$ p(s', r \\mid s, a) \\quad \\forall s, s', r, a $$  \n",
    "- **Factor de descuento**:  \n",
    "  $$ \\gamma $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen las razones de probabilidad del dado cargado, lo que significa que las probailidades no son uniformes, algunas tienen m谩s probabilidad de salir que otras. En lugar de un dado justo con una probabilidad uniforme de 1/6, aqu铆 se asignan valores espec铆ficos: sacar un 1 o 6 tiene una probabilidad de 10%, un 2 o un 5 ocurre el 15% del tiempo, y un 3 o un 4 sucede con mayor frecuencia (20%). Esto afecta las transiciones del MDP, ya que los valores medios (3 y 4) ser谩n m谩s comunes, influyendo en la estrategia 贸ptima del jugador al moverse en el tablero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades = np.array([0.1, 0.2, 0.3, 0.2, 0.1, 0.1])  # dado cargado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n, se definen dos diccionarios en Python que modelan las escaleras y serpientes del tablero, donde las claves representan las casillas de inicio y los valores indican las casillas destino. El diccionario escaleras indica las casillas donde un jugador avanza autom谩ticamente a una posici贸n m谩s alta, mientras que serpientes representa las casillas que obligan al jugador a retroceder, dificultando su progreso. Estas transiciones no lineales afectan la din谩mica del juego y se incorporan en la funci贸n de probabilidad de transici贸n del MDP, asegurando que el modelo refleje correctamente las reglas del juego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir posiciones de escaleras y serpientes\n",
    "escaleras = {8: 26, 21: 82, 43: 77, 50: 91, 54: 93, 66: 87, 62: 96, 80: 100} # modelado de 8 escaleras\n",
    "serpientes = {52: 11, 69: 33, 92: 51, 48: 9, 73: 1, 55: 7, 46: 5, 95: 24, 64: 36, 44: 22, 98: 28, 83: 19, 59: 17} # modelado de serpientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen mediante listas, los estados correspondientes a victoria o derrota denotados en la grafica de color azul y rojo respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casillas de ganar y perder\n",
    "estadoGanar = [80, 100]  # Casillas azules\n",
    "estadoPerder = [23, 37, 45, 67, 89]  # Casillas rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se modela la variable gamma que en el MDP permite dar relevancia a la evoluci贸n de los estados en el tiempo, el valor de 0.9 se parametriza para dar mayor relevancia a los estados recientes en comparaci贸n a los estados m谩s antiguos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor de descuento\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se modela una funci贸n que modela las probabbilidades de transici贸n en el talero de juego, esta calcula la distribuci贸n de probabilidad de transici贸n en el tablero de escaleras y serpientes, modelando c贸mo un jugador se mover谩 desde un estado actual  tras tomar una acci贸n  y lanzar el dado. Para cada posible resultado del dado, ajusta el estado futuro sumando o restando el valor obtenido seg煤n la acci贸n tomada. Luego, maneja los rebotes en los extremos del tablero si el jugador supera la casilla 100 o cae por debajo de la casilla 1. Posteriormente, aplica las reglas de escaleras y serpientes, trasladando al jugador si cae en una de estas casillas. Finalmente, almacena la probabilidad acumulada de alcanzar cada estado en un vector, asegurando que la suma total de probabilidades sea 1, y lo retorna, permitiendo definir la matriz de transici贸n (测ｐ,) clave en el MDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_nuevo_estado(s, a, resultado_dado):\n",
    "    # Verificar si el estado actual es terminal\n",
    "    if s in estadoGanar or s in estadoPerder:\n",
    "        return s  # No se mueve si ya est谩 en un estado terminal\n",
    "\n",
    "    # Calcular el nuevo estado seg煤n la acci贸n\n",
    "    if a == \"avanzar\":\n",
    "        nuevo_s = s + resultado_dado\n",
    "    elif a == \"retroceder\":\n",
    "        nuevo_s = s - resultado_dado\n",
    "    else:\n",
    "        raise ValueError(\"Acci贸n no v谩lida\")\n",
    "\n",
    "    # Rebote en los extremos (solo si no es un estado terminal)\n",
    "    if nuevo_s > 100:\n",
    "        nuevo_s = 100 - (nuevo_s - 100)  # Rebote si se supera 100\n",
    "    elif nuevo_s < 1:\n",
    "        nuevo_s = 100 - (1 - nuevo_s)  # Rebote si se retrocede m谩s all谩 de 1\n",
    "\n",
    "    # Verificar si el nuevo estado es terminal\n",
    "    if nuevo_s in estadoGanar or nuevo_s in estadoPerder:\n",
    "        return nuevo_s  # No se aplican escaleras o serpientes en estados terminales\n",
    "\n",
    "    # Escaleras\n",
    "    if nuevo_s in escaleras:\n",
    "        nuevo_s = escaleras[nuevo_s]\n",
    "\n",
    "    # Serpientes\n",
    "    if nuevo_s in serpientes:\n",
    "        nuevo_s = serpientes[nuevo_s]\n",
    "\n",
    "    return nuevo_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se modela la funci贸n de recomensas, esta asigna una recompensa a cada estado  seg煤n su impacto en el juego, retornando +1 si el jugador alcanza una casilla de victoria (estadoGanar), -1 si cae en una casilla de derrota (estadoPerder), y -0.01 en cualquier otro caso como penalizaci贸n por movimiento, incentivando as铆 estrategias que minimicen el n煤mero de pasos y maximicen la recompensa total en el MDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_recompensa(s):\n",
    "    if s in estadoGanar:\n",
    "        return 100\n",
    "    elif s in estadoPerder:\n",
    "        return -100\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci贸n para simular un paso en el MDP\n",
    "def paso_mdp(s, a):\n",
    "    # Lanzar el dado\n",
    "    resultado_dado = np.random.choice([1, 2, 3, 4, 5, 6], p=probabilidades)\n",
    "\n",
    "    # Calcular nuevo estado\n",
    "    nuevo_s = calcular_nuevo_estado(s, a, resultado_dado)\n",
    "\n",
    "    # Obtener recompensa\n",
    "    r = obtener_recompensa(nuevo_s)\n",
    "\n",
    "    # Verificar si el estado es terminal\n",
    "    terminal = (nuevo_s in estadoGanar) or (nuevo_s in estadoPerder)\n",
    "\n",
    "    return nuevo_s, r, terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado: 7, Recompensa: -1\n",
      "Estado: 9, Recompensa: -1\n",
      "Estado: 14, Recompensa: -1\n",
      "Estado: 16, Recompensa: -1\n",
      "Estado: 19, Recompensa: -1\n",
      "Estado: 24, Recompensa: -1\n",
      "Estado: 27, Recompensa: -1\n",
      "Estado: 30, Recompensa: -1\n",
      "Estado: 34, Recompensa: -1\n",
      "Estado: 40, Recompensa: -1\n",
      "Estado: 77, Recompensa: -1\n",
      "Estado: 19, Recompensa: -1\n",
      "Estado: 25, Recompensa: -1\n",
      "Estado: 29, Recompensa: -1\n",
      "Estado: 33, Recompensa: -1\n",
      "Estado: 39, Recompensa: -1\n",
      "Estado: 22, Recompensa: -1\n",
      "Estado: 28, Recompensa: -1\n",
      "Estado: 31, Recompensa: -1\n",
      "Estado: 34, Recompensa: -1\n",
      "Estado: 36, Recompensa: -1\n",
      "Estado: 40, Recompensa: -1\n",
      "Estado: 22, Recompensa: -1\n",
      "Estado: 25, Recompensa: -1\n",
      "Estado: 27, Recompensa: -1\n",
      "Estado: 33, Recompensa: -1\n",
      "Estado: 39, Recompensa: -1\n",
      "Estado: 41, Recompensa: -1\n",
      "Estado: 22, Recompensa: -1\n",
      "Estado: 28, Recompensa: -1\n",
      "Estado: 31, Recompensa: -1\n",
      "Estado: 34, Recompensa: -1\n",
      "Estado: 40, Recompensa: -1\n",
      "Estado: 5, Recompensa: -1\n",
      "Estado: 9, Recompensa: -1\n",
      "Estado: 11, Recompensa: -1\n",
      "Estado: 15, Recompensa: -1\n",
      "Estado: 82, Recompensa: -1\n",
      "Estado: 87, Recompensa: -1\n",
      "Estado: 91, Recompensa: -1\n",
      "Estado: 93, Recompensa: -1\n",
      "Estado: 99, Recompensa: -1\n",
      "Estado: 28, Recompensa: -1\n",
      "Estado: 29, Recompensa: -1\n",
      "Estado: 32, Recompensa: -1\n",
      "Estado: 35, Recompensa: -1\n",
      "Estado: 38, Recompensa: -1\n",
      "Estado: 41, Recompensa: -1\n",
      "Estado: 45, Recompensa: -100\n",
      "Fin del juego.\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de simulaci贸n\n",
    "def simular_juego():\n",
    "    s = 1  # Estado inicial\n",
    "    historial = []\n",
    "    terminal = False\n",
    "\n",
    "    while not terminal:\n",
    "        a = \"avanzar\" # Elegir acci贸n (en este ejemplo, siempre avanzar)\n",
    "        s, r, terminal = paso_mdp(s, a) # Tomar un paso en el MDP       \n",
    "        historial.append((s, r)) # Guardar historial\n",
    "        print(f\"Estado: {s}, Recompensa: {r}\")\n",
    "\n",
    "    print(\"Fin del juego.\")\n",
    "    return historial\n",
    "\n",
    "# Ejecutar simulaci贸n\n",
    "historial = simular_juego()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Veificaci贸n del MDP:\n",
    "\n",
    "Se realizan verificaciones para corroborar que el MDP est谩 correctamente estructurado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se verifica que cada estado tiene una distribuci贸n de probabilidad v谩lida mediante la suma de probabilidades de transici贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que no hay estados repetidos o no v谩lidos\n",
    "estados = set(range(1, 101))  # Estados del 1 al 100\n",
    "estados_terminales = set(estadoGanar + estadoPerder)\n",
    "\n",
    "# Verificar que los estados terminales est谩n dentro del rango\n",
    "assert all(s in estados for s in estados_terminales), \"Estados terminales no v谩lidos\"\n",
    "\n",
    "# Verificar que no hay solapamientos entre estados de ganar y perder\n",
    "assert len(set(estadoGanar).intersection(set(estadoPerder))) == 0, \"Solapamiento entre estados de ganar y perder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que las acciones son v谩lidas\n",
    "acciones_validas = {\"avanzar\", \"retroceder\"}\n",
    "acciones = {\"avanzar\", \"retroceder\"}\n",
    "\n",
    "assert acciones.issubset(acciones_validas), \"Acciones no v谩lidas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar recompensas en estados terminales\n",
    "for s in estadoGanar:\n",
    "    assert obtener_recompensa(s) == 100, f\"Recompensa incorrecta en estado ganar {s}\"\n",
    "\n",
    "for s in estadoPerder:\n",
    "    assert obtener_recompensa(s) == -100, f\"Recompensa incorrecta en estado perder {s}\"\n",
    "\n",
    "# Verificar recompensas en estados no terminales\n",
    "for s in range(1, 101):\n",
    "    if s not in estadoGanar and s not in estadoPerder:\n",
    "        assert obtener_recompensa(s) == -1, f\"Recompensa incorrecta en estado no terminal {s}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Error en rebote al retroceder m谩s all谩 de 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m calcular_nuevo_estado(\u001b[32m99\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mavanzar\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m) == \u001b[32m100\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mError al llegar a 100\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Verificar rebote al retroceder m谩s all谩 de 1\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m calcular_nuevo_estado(\u001b[32m2\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mretroceder\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2\u001b[39m) == \u001b[32m100\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mError en rebote al retroceder m谩s all谩 de 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Verificar que no hay rebote en estados terminales\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m calcular_nuevo_estado(\u001b[32m100\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mavanzar\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2\u001b[39m) == \u001b[32m100\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mError: Rebote en estado terminal 100\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: Error en rebote al retroceder m谩s all谩 de 1"
     ]
    }
   ],
   "source": [
    "# Verificar que al avanzar desde 99 con un dado de 1, el jugador llega a 100 (estado terminal)\n",
    "assert calcular_nuevo_estado(99, \"avanzar\", 1) == 100, \"Error al llegar a 100\"\n",
    "\n",
    "# Verificar rebote al retroceder m谩s all谩 de 1\n",
    "assert calcular_nuevo_estado(2, \"retroceder\", 2) == 100, \"Error en rebote al retroceder m谩s all谩 de 1\"\n",
    "\n",
    "# Verificar que no hay rebote en estados terminales\n",
    "assert calcular_nuevo_estado(100, \"avanzar\", 2) == 100, \"Error: Rebote en estado terminal 100\"\n",
    "assert calcular_nuevo_estado(80, \"avanzar\", 2) == 80, \"Error: Rebote en estado terminal 80\"\n",
    "assert calcular_nuevo_estado(23, \"avanzar\", 2) == 23, \"Error: Rebote en estado terminal 23\"\n",
    "\n",
    "# Verificar escaleras\n",
    "assert calcular_nuevo_estado(8, \"avanzar\", 1) == 26, \"Error en escalera en casilla 8\"\n",
    "assert calcular_nuevo_estado(21, \"avanzar\", 1) == 82, \"Error en escalera en casilla 21\"\n",
    "\n",
    "# Verificar serpientes\n",
    "assert calcular_nuevo_estado(52, \"avanzar\", 1) == 11, \"Error en serpiente en casilla 52\"\n",
    "assert calcular_nuevo_estado(69, \"avanzar\", 1) == 33, \"Error en serpiente en casilla 69\"\n",
    "\n",
    "# Verificar que no hay bucles infinitos (por ejemplo, escaleras que llevan a serpientes y viceversa)\n",
    "for s in escaleras:\n",
    "    assert escaleras[s] not in serpientes, f\"Escalera en {s} lleva a una serpiente\"\n",
    "\n",
    "for s in serpientes:\n",
    "    assert serpientes[s] not in escaleras, f\"Serpiente en {s} lleva a una escalera\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 <= gamma <= 1, \"Factor de descuento no v谩lido\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prob_dado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m np.isclose(suma_probabilidades, \u001b[32m1\u001b[39m), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError en la funci贸n de transici贸n para s=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, a=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Verificar para algunos estados y acciones\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mverificar_transicion\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mavanzar\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m verificar_transicion(\u001b[32m50\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mretroceder\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m verificar_transicion(\u001b[32m99\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mavanzar\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mverificar_transicion\u001b[39m\u001b[34m(s, a)\u001b[39m\n\u001b[32m      5\u001b[39m     nuevo_s = calcular_nuevo_estado(s, a, resultado_dado)\n\u001b[32m      6\u001b[39m     r = obtener_recompensa(nuevo_s)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     transiciones[(nuevo_s, r)] = transiciones.get((nuevo_s, r), \u001b[32m0\u001b[39m) + \u001b[43mprob_dado\u001b[49m[resultado_dado - \u001b[32m1\u001b[39m]\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Verificar que la suma de probabilidades es 1\u001b[39;00m\n\u001b[32m     10\u001b[39m suma_probabilidades = \u001b[38;5;28msum\u001b[39m(transiciones.values())\n",
      "\u001b[31mNameError\u001b[39m: name 'prob_dado' is not defined"
     ]
    }
   ],
   "source": [
    "def verificar_transicion(s, a):\n",
    "    # Calcular todas las transiciones posibles desde el estado s con la acci贸n a\n",
    "    transiciones = {}\n",
    "    for resultado_dado in range(1, 7):\n",
    "        nuevo_s = calcular_nuevo_estado(s, a, resultado_dado)\n",
    "        r = obtener_recompensa(nuevo_s)\n",
    "        transiciones[(nuevo_s, r)] = transiciones.get((nuevo_s, r), 0) + prob_dado[resultado_dado - 1]\n",
    "\n",
    "    # Verificar que la suma de probabilidades es 1\n",
    "    suma_probabilidades = sum(transiciones.values())\n",
    "    assert np.isclose(suma_probabilidades, 1), f\"Error en la funci贸n de transici贸n para s={s}, a={a}\"\n",
    "\n",
    "# Verificar para algunos estados y acciones\n",
    "verificar_transicion(1, \"avanzar\")\n",
    "verificar_transicion(50, \"retroceder\")\n",
    "verificar_transicion(99, \"avanzar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_episodio():\n",
    "    s = 1  # Estado inicial\n",
    "    terminal = False\n",
    "    pasos = 0\n",
    "\n",
    "    while not terminal:\n",
    "        a = \"avanzar\"  # Siempre avanzar para simplificar\n",
    "        s, r, terminal = paso_mdp(s, a)\n",
    "        pasos += 1\n",
    "\n",
    "        # Verificar que no se excede un n煤mero razonable de pasos\n",
    "        assert pasos <= 1000, \"El episodio no termin贸 en un n煤mero razonable de pasos\"\n",
    "\n",
    "    # Verificar que el estado final es terminal\n",
    "    assert s in estadoGanar or s in estadoPerder, \"El episodio no termin贸 en un estado terminal\"\n",
    "\n",
    "# Ejecutar varias simulaciones para verificar\n",
    "for _ in range(100):\n",
    "    verificar_episodio()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
