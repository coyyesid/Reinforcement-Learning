{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tarea 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Punto 1:_\n",
    "\n",
    "### 1. Modelado del problema como un MDP\n",
    "\n",
    "Modele este problema como un MDP. Detalle todos los elementos del MDP:\n",
    "\n",
    "- **Estados**  \n",
    "- **Recompensas**  \n",
    "- **Acciones**  \n",
    "- **Dinámica de transición**:  \n",
    "  $$ p(s', r \\mid s, a) \\quad \\forall s, s', r, a $$  \n",
    "- **Factor de descuento**:  \n",
    "  $$ \\gamma $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen las razones de probabilidad del dado cargado, lo que significa que las probailidades no son uniformes, algunas tienen más probabilidad de salir que otras. En lugar de un dado justo con una probabilidad uniforme de 1/6, aquí se asignan valores específicos: sacar un 1 o 6 tiene una probabilidad de 10%, un 2 o un 5 ocurre el 15% del tiempo, y un 3 o un 4 sucede con mayor frecuencia (20%). Esto afecta las transiciones del MDP, ya que los valores medios (3 y 4) serán más comunes, influyendo en la estrategia óptima del jugador al moverse en el tablero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades = np.array([0.1, 0.2, 0.3, 0.2, 0.1, 0.1])  # dado cargado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se definen dos diccionarios en Python que modelan las escaleras y serpientes del tablero, donde las claves representan las casillas de inicio y los valores indican las casillas destino. El diccionario escaleras indica las casillas donde un jugador avanza automáticamente a una posición más alta, mientras que serpientes representa las casillas que obligan al jugador a retroceder, dificultando su progreso. Estas transiciones no lineales afectan la dinámica del juego y se incorporan en la función de probabilidad de transición del MDP, asegurando que el modelo refleje correctamente las reglas del juego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir posiciones de escaleras y serpientes\n",
    "escaleras = {8: 26, 21: 82, 43: 77, 50: 91, 54: 93, 66: 87, 62: 96, 80: 100} # modelado de 8 escaleras\n",
    "serpientes = {52: 11, 69: 33, 92: 51, 48: 9, 73: 1, 55: 7, 46: 5, 95: 24, 64: 36, 44: 22, 98: 28, 83: 19, 59: 17} # modelado de serpientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen mediante listas, los estados correspondientes a victoria o derrota denotados en la grafica de color azul y rojo respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casillas de ganar y perder\n",
    "estadoGanar = [80, 100]  # Casillas azules\n",
    "estadoPerder = [23, 37, 45, 67, 89]  # Casillas rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se modela la variable gamma que en el MDP permite dar relevancia a la evolución de los estados en el tiempo, el valor de 0.9 se parametriza para dar mayor relevancia a los estados recientes en comparación a los estados más antiguos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor de descuento\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se modela una función que modela las probabbilidades de transición en el talero de juego, esta calcula la distribución de probabilidad de transición en el tablero de escaleras y serpientes, modelando cómo un jugador se moverá desde un estado actual 𝑠 tras tomar una acción 𝑎 y lanzar el dado. Para cada posible resultado del dado, ajusta el estado futuro sumando o restando el valor obtenido según la acción tomada. Luego, maneja los rebotes en los extremos del tablero si el jugador supera la casilla 100 o cae por debajo de la casilla 1. Posteriormente, aplica las reglas de escaleras y serpientes, trasladando al jugador si cae en una de estas casillas. Finalmente, almacena la probabilidad acumulada de alcanzar cada estado en un vector, asegurando que la suma total de probabilidades sea 1, y lo retorna, permitiendo definir la matriz de transición 𝑃(𝑠′∣𝑠,𝑎) clave en el MDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_nuevo_estado(s, a, resultado_dado):\n",
    "    # Verificar si el estado actual es terminal\n",
    "    if s in estadoGanar or s in estadoPerder:\n",
    "        return s  # No se mueve si ya está en un estado terminal\n",
    "\n",
    "    # Calcular el nuevo estado según la acción\n",
    "    if a == \"avanzar\":\n",
    "        nuevo_s = s + resultado_dado\n",
    "    elif a == \"retroceder\":\n",
    "        nuevo_s = s - resultado_dado\n",
    "    else:\n",
    "        raise ValueError(\"Acción no válida\")\n",
    "\n",
    "    # Rebote en los extremos (solo si no es un estado terminal)\n",
    "    if nuevo_s > 100:\n",
    "        nuevo_s = 100 - (nuevo_s - 100)  # Rebote si se supera 100\n",
    "    elif nuevo_s < 1:\n",
    "        nuevo_s = 100 - (1 - nuevo_s)  # Rebote si se retrocede más allá de 1\n",
    "\n",
    "    # Verificar si el nuevo estado es terminal\n",
    "    if nuevo_s in estadoGanar or nuevo_s in estadoPerder:\n",
    "        return nuevo_s  # No se aplican escaleras o serpientes en estados terminales\n",
    "\n",
    "    # Escaleras\n",
    "    if nuevo_s in escaleras:\n",
    "        nuevo_s = escaleras[nuevo_s]\n",
    "\n",
    "    # Serpientes\n",
    "    if nuevo_s in serpientes:\n",
    "        nuevo_s = serpientes[nuevo_s]\n",
    "\n",
    "    return nuevo_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se modela la función de recomensas, esta asigna una recompensa a cada estado 𝑠 según su impacto en el juego, retornando +1 si el jugador alcanza una casilla de victoria (estadoGanar), -1 si cae en una casilla de derrota (estadoPerder), y -0.01 en cualquier otro caso como penalización por movimiento, incentivando así estrategias que minimicen el número de pasos y maximicen la recompensa total en el MDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_recompensa(s):\n",
    "    if s in estadoGanar:\n",
    "        return 100\n",
    "    elif s in estadoPerder:\n",
    "        return -100\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para simular un paso en el MDP\n",
    "def paso_mdp(s, a):\n",
    "    # Lanzar el dado\n",
    "    resultado_dado = np.random.choice([1, 2, 3, 4, 5, 6], p=probabilidades)\n",
    "\n",
    "    # Calcular nuevo estado\n",
    "    nuevo_s = calcular_nuevo_estado(s, a, resultado_dado)\n",
    "\n",
    "    # Obtener recompensa\n",
    "    r = obtener_recompensa(nuevo_s)\n",
    "\n",
    "    # Verificar si el estado es terminal\n",
    "    terminal = (nuevo_s in estadoGanar) or (nuevo_s in estadoPerder)\n",
    "\n",
    "    return nuevo_s, r, terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado: 7, Recompensa: -1\n",
      "Estado: 9, Recompensa: -1\n",
      "Estado: 14, Recompensa: -1\n",
      "Estado: 16, Recompensa: -1\n",
      "Estado: 19, Recompensa: -1\n",
      "Estado: 24, Recompensa: -1\n",
      "Estado: 27, Recompensa: -1\n",
      "Estado: 30, Recompensa: -1\n",
      "Estado: 34, Recompensa: -1\n",
      "Estado: 40, Recompensa: -1\n",
      "Estado: 77, Recompensa: -1\n",
      "Estado: 19, Recompensa: -1\n",
      "Estado: 25, Recompensa: -1\n",
      "Estado: 29, Recompensa: -1\n",
      "Estado: 33, Recompensa: -1\n",
      "Estado: 39, Recompensa: -1\n",
      "Estado: 22, Recompensa: -1\n",
      "Estado: 28, Recompensa: -1\n",
      "Estado: 31, Recompensa: -1\n",
      "Estado: 34, Recompensa: -1\n",
      "Estado: 36, Recompensa: -1\n",
      "Estado: 40, Recompensa: -1\n",
      "Estado: 22, Recompensa: -1\n",
      "Estado: 25, Recompensa: -1\n",
      "Estado: 27, Recompensa: -1\n",
      "Estado: 33, Recompensa: -1\n",
      "Estado: 39, Recompensa: -1\n",
      "Estado: 41, Recompensa: -1\n",
      "Estado: 22, Recompensa: -1\n",
      "Estado: 28, Recompensa: -1\n",
      "Estado: 31, Recompensa: -1\n",
      "Estado: 34, Recompensa: -1\n",
      "Estado: 40, Recompensa: -1\n",
      "Estado: 5, Recompensa: -1\n",
      "Estado: 9, Recompensa: -1\n",
      "Estado: 11, Recompensa: -1\n",
      "Estado: 15, Recompensa: -1\n",
      "Estado: 82, Recompensa: -1\n",
      "Estado: 87, Recompensa: -1\n",
      "Estado: 91, Recompensa: -1\n",
      "Estado: 93, Recompensa: -1\n",
      "Estado: 99, Recompensa: -1\n",
      "Estado: 28, Recompensa: -1\n",
      "Estado: 29, Recompensa: -1\n",
      "Estado: 32, Recompensa: -1\n",
      "Estado: 35, Recompensa: -1\n",
      "Estado: 38, Recompensa: -1\n",
      "Estado: 41, Recompensa: -1\n",
      "Estado: 45, Recompensa: -100\n",
      "Fin del juego.\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de simulación\n",
    "def simular_juego():\n",
    "    s = 1  # Estado inicial\n",
    "    historial = []\n",
    "    terminal = False\n",
    "\n",
    "    while not terminal:\n",
    "        a = \"avanzar\" # Elegir acción (en este ejemplo, siempre avanzar)\n",
    "        s, r, terminal = paso_mdp(s, a) # Tomar un paso en el MDP       \n",
    "        historial.append((s, r)) # Guardar historial\n",
    "        print(f\"Estado: {s}, Recompensa: {r}\")\n",
    "\n",
    "    print(\"Fin del juego.\")\n",
    "    return historial\n",
    "\n",
    "# Ejecutar simulación\n",
    "historial = simular_juego()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Veificación del MDP:\n",
    "\n",
    "Se realizan verificaciones para corroborar que el MDP está correctamente estructurado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se verifica que cada estado tiene una distribución de probabilidad válida mediante la suma de probabilidades de transición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que no hay estados repetidos o no válidos\n",
    "estados = set(range(1, 101))  # Estados del 1 al 100\n",
    "estados_terminales = set(estadoGanar + estadoPerder)\n",
    "\n",
    "# Verificar que los estados terminales están dentro del rango\n",
    "assert all(s in estados for s in estados_terminales), \"Estados terminales no válidos\"\n",
    "\n",
    "# Verificar que no hay solapamientos entre estados de ganar y perder\n",
    "assert len(set(estadoGanar).intersection(set(estadoPerder))) == 0, \"Solapamiento entre estados de ganar y perder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que las acciones son válidas\n",
    "acciones_validas = {\"avanzar\", \"retroceder\"}\n",
    "acciones = {\"avanzar\", \"retroceder\"}\n",
    "\n",
    "assert acciones.issubset(acciones_validas), \"Acciones no válidas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar recompensas en estados terminales\n",
    "for s in estadoGanar:\n",
    "    assert obtener_recompensa(s) == 100, f\"Recompensa incorrecta en estado ganar {s}\"\n",
    "\n",
    "for s in estadoPerder:\n",
    "    assert obtener_recompensa(s) == -100, f\"Recompensa incorrecta en estado perder {s}\"\n",
    "\n",
    "# Verificar recompensas en estados no terminales\n",
    "for s in range(1, 101):\n",
    "    if s not in estadoGanar and s not in estadoPerder:\n",
    "        assert obtener_recompensa(s) == -1, f\"Recompensa incorrecta en estado no terminal {s}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Error en rebote al retroceder más allá de 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m calcular_nuevo_estado(\u001b[32m99\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mavanzar\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m) == \u001b[32m100\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mError al llegar a 100\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Verificar rebote al retroceder más allá de 1\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m calcular_nuevo_estado(\u001b[32m2\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mretroceder\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2\u001b[39m) == \u001b[32m100\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mError en rebote al retroceder más allá de 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Verificar que no hay rebote en estados terminales\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m calcular_nuevo_estado(\u001b[32m100\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mavanzar\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2\u001b[39m) == \u001b[32m100\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mError: Rebote en estado terminal 100\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: Error en rebote al retroceder más allá de 1"
     ]
    }
   ],
   "source": [
    "# Verificar que al avanzar desde 99 con un dado de 1, el jugador llega a 100 (estado terminal)\n",
    "assert calcular_nuevo_estado(99, \"avanzar\", 1) == 100, \"Error al llegar a 100\"\n",
    "\n",
    "# Verificar rebote al retroceder más allá de 1\n",
    "assert calcular_nuevo_estado(2, \"retroceder\", 2) == 100, \"Error en rebote al retroceder más allá de 1\"\n",
    "\n",
    "# Verificar que no hay rebote en estados terminales\n",
    "assert calcular_nuevo_estado(100, \"avanzar\", 2) == 100, \"Error: Rebote en estado terminal 100\"\n",
    "assert calcular_nuevo_estado(80, \"avanzar\", 2) == 80, \"Error: Rebote en estado terminal 80\"\n",
    "assert calcular_nuevo_estado(23, \"avanzar\", 2) == 23, \"Error: Rebote en estado terminal 23\"\n",
    "\n",
    "# Verificar escaleras\n",
    "assert calcular_nuevo_estado(8, \"avanzar\", 1) == 26, \"Error en escalera en casilla 8\"\n",
    "assert calcular_nuevo_estado(21, \"avanzar\", 1) == 82, \"Error en escalera en casilla 21\"\n",
    "\n",
    "# Verificar serpientes\n",
    "assert calcular_nuevo_estado(52, \"avanzar\", 1) == 11, \"Error en serpiente en casilla 52\"\n",
    "assert calcular_nuevo_estado(69, \"avanzar\", 1) == 33, \"Error en serpiente en casilla 69\"\n",
    "\n",
    "# Verificar que no hay bucles infinitos (por ejemplo, escaleras que llevan a serpientes y viceversa)\n",
    "for s in escaleras:\n",
    "    assert escaleras[s] not in serpientes, f\"Escalera en {s} lleva a una serpiente\"\n",
    "\n",
    "for s in serpientes:\n",
    "    assert serpientes[s] not in escaleras, f\"Serpiente en {s} lleva a una escalera\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 <= gamma <= 1, \"Factor de descuento no válido\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prob_dado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m np.isclose(suma_probabilidades, \u001b[32m1\u001b[39m), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError en la función de transición para s=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, a=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Verificar para algunos estados y acciones\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mverificar_transicion\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mavanzar\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m verificar_transicion(\u001b[32m50\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mretroceder\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m verificar_transicion(\u001b[32m99\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mavanzar\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mverificar_transicion\u001b[39m\u001b[34m(s, a)\u001b[39m\n\u001b[32m      5\u001b[39m     nuevo_s = calcular_nuevo_estado(s, a, resultado_dado)\n\u001b[32m      6\u001b[39m     r = obtener_recompensa(nuevo_s)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     transiciones[(nuevo_s, r)] = transiciones.get((nuevo_s, r), \u001b[32m0\u001b[39m) + \u001b[43mprob_dado\u001b[49m[resultado_dado - \u001b[32m1\u001b[39m]\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Verificar que la suma de probabilidades es 1\u001b[39;00m\n\u001b[32m     10\u001b[39m suma_probabilidades = \u001b[38;5;28msum\u001b[39m(transiciones.values())\n",
      "\u001b[31mNameError\u001b[39m: name 'prob_dado' is not defined"
     ]
    }
   ],
   "source": [
    "def verificar_transicion(s, a):\n",
    "    # Calcular todas las transiciones posibles desde el estado s con la acción a\n",
    "    transiciones = {}\n",
    "    for resultado_dado in range(1, 7):\n",
    "        nuevo_s = calcular_nuevo_estado(s, a, resultado_dado)\n",
    "        r = obtener_recompensa(nuevo_s)\n",
    "        transiciones[(nuevo_s, r)] = transiciones.get((nuevo_s, r), 0) + prob_dado[resultado_dado - 1]\n",
    "\n",
    "    # Verificar que la suma de probabilidades es 1\n",
    "    suma_probabilidades = sum(transiciones.values())\n",
    "    assert np.isclose(suma_probabilidades, 1), f\"Error en la función de transición para s={s}, a={a}\"\n",
    "\n",
    "# Verificar para algunos estados y acciones\n",
    "verificar_transicion(1, \"avanzar\")\n",
    "verificar_transicion(50, \"retroceder\")\n",
    "verificar_transicion(99, \"avanzar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_episodio():\n",
    "    s = 1  # Estado inicial\n",
    "    terminal = False\n",
    "    pasos = 0\n",
    "\n",
    "    while not terminal:\n",
    "        a = \"avanzar\"  # Siempre avanzar para simplificar\n",
    "        s, r, terminal = paso_mdp(s, a)\n",
    "        pasos += 1\n",
    "\n",
    "        # Verificar que no se excede un número razonable de pasos\n",
    "        assert pasos <= 1000, \"El episodio no terminó en un número razonable de pasos\"\n",
    "\n",
    "    # Verificar que el estado final es terminal\n",
    "    assert s in estadoGanar or s in estadoPerder, \"El episodio no terminó en un estado terminal\"\n",
    "\n",
    "# Ejecutar varias simulaciones para verificar\n",
    "for _ in range(100):\n",
    "    verificar_episodio()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
