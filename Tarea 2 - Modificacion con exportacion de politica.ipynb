{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tarea 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen las librerias requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Punto 1:_\n",
    "\n",
    "### Modelado del problema como un MDP\n",
    "\n",
    "Modele este problema como un MDP. Detalle todos los elementos del MDP:\n",
    "\n",
    "- **Estados**  \n",
    "- **Recompensas**  \n",
    "- **Acciones**  \n",
    "- **Dinámica de transición**:  \n",
    "  $$ p(s', r \\mid s, a) \\quad \\forall s, s', r, a $$  \n",
    "- **Factor de descuento**:  \n",
    "  $$ \\gamma $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen las razones de probabilidad del dado cargado, lo que significa que las probailidades no son uniformes, algunas tienen más probabilidad de salir que otras. En lugar de un dado justo con una probabilidad uniforme de 1/6, aquí se asignan valores específicos: sacar un 1 o 6 tiene una probabilidad de 10%, un 2 o un 5 ocurre el 15% del tiempo, y un 3 o un 4 sucede con mayor frecuencia (20%). Esto afecta las transiciones del MDP, ya que los valores medios (3 y 4) serán más comunes, influyendo en la estrategia óptima del jugador al moverse en el tablero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades = np.array([0.1, 0.2, 0.3, 0.2, 0.1, 0.1])  # dado cargado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se definen dos diccionarios en Python que modelan las escaleras y serpientes del tablero, donde las claves representan las casillas de inicio y los valores indican las casillas destino. El diccionario escaleras indica las casillas donde un jugador avanza automáticamente a una posición más alta, mientras que serpientes representa las casillas que obligan al jugador a retroceder, dificultando su progreso. Estas transiciones no lineales afectan la dinámica del juego y se incorporan en la función de probabilidad de transición del MDP, asegurando que el modelo refleje correctamente las reglas del juego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir posiciones de escaleras y serpientes\n",
    "escaleras = {8: 26, 21: 82, 43: 77, 50: 91, 54: 93, 66: 87, 62: 96} # modelado de 7 escaleras, la escalera que conecta los estados 80 y 100, por practicidad no se considera al ser ambos estados terminales de victoria.\n",
    "serpientes = {52: 11, 69: 33, 92: 51, 48: 9, 73: 1, 55: 7, 46: 5, 95: 24, 64: 36, 44: 22, 98: 28, 83: 19, 59: 17} # modelado de serpientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la constante gamma dada por el ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen mediante listas, los estados correspondientes a victoria o derrota denotados en la grafica de color azul y rojo respectivamente, así como los estados terminales en conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estados especiales\n",
    "estadoGanar = [80, 100]\n",
    "estadoPerder = [23, 37, 45, 67, 89]\n",
    "estadosTerminales = set(estadoGanar + estadoPerder)\n",
    "estadosInvalidos = set(escaleras.keys()).union(set(serpientes.keys()))\n",
    "estadosValidos = set(range(1, 101)) - estadosTerminales - estadosInvalidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inicializa la tabla de valor de estado, poniendo los valores en 0, y se inicializan las recompensas, como se establece en el tablero del ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de estados y recompensas\n",
    "valoresEstado = {s: 0 for s in range(1, 101)}\n",
    "recompensasEstado = {s: (100 if s in estadoGanar else -100 if s in estadoPerder else -1) for s in range(1, 101)}\n",
    "acciones = [\"avanzar\", \"retroceder\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra la matriz inicial con los valores de estado inicializados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz Inicial de Valores de Estado (10x10):\n",
      "   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n",
      "   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n",
      "   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n",
      "   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n",
      "   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n",
      "   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n",
      "   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n",
      "   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n",
      "   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n",
      "   0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n"
     ]
    }
   ],
   "source": [
    "def mostrarMatrizInicial():\n",
    "    matriz = np.zeros((10, 10), dtype=object)\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            estado = i * 10 + (j + 1 if i % 2 == 0 else 10 - j)\n",
    "            matriz[9 - i, j] = f\"{valoresEstado[estado]:7.2f}\"\n",
    "    print(\"\\nMatriz Inicial de Valores de Estado (10x10):\")\n",
    "    for fila in matriz:\n",
    "        print(\" \".join(str(valor) for valor in fila))\n",
    "\n",
    "mostrarMatrizInicial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra la distribución de recompensas esstablecida para el ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Recompensas por Estado (10x10):\n",
      "    100      -1      -1      -1      -1      -1      -1      -1      -1      -1\n",
      "     -1      -1      -1      -1      -1      -1      -1      -1    -100      -1\n",
      "    100      -1      -1      -1      -1      -1      -1      -1      -1      -1\n",
      "     -1      -1      -1      -1      -1      -1    -100      -1      -1      -1\n",
      "     -1      -1      -1      -1      -1      -1      -1      -1      -1      -1\n",
      "     -1      -1      -1      -1    -100      -1      -1      -1      -1      -1\n",
      "     -1      -1      -1    -100      -1      -1      -1      -1      -1      -1\n",
      "     -1      -1    -100      -1      -1      -1      -1      -1      -1      -1\n",
      "     -1      -1      -1      -1      -1      -1      -1      -1      -1      -1\n",
      "     -1      -1      -1      -1      -1      -1      -1      -1      -1      -1\n"
     ]
    }
   ],
   "source": [
    "def mostrarMatrizRecompensas():\n",
    "    matriz = np.zeros((10, 10), dtype=object)\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            estado = i * 10 + (j + 1 if i % 2 == 0 else 10 - j)\n",
    "            matriz[9 - i, j] = f\"{recompensasEstado[estado]:7d}\"\n",
    "    print(\"\\nMatriz de Recompensas por Estado (10x10):\")\n",
    "    for fila in matriz:\n",
    "        print(\" \".join(str(valor) for valor in fila))\n",
    "\n",
    "mostrarMatrizRecompensas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una función para graficar las recompensas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrarGraficoRecompensas(recompensas):\n",
    "    plt.plot(recompensas)\n",
    "    plt.xlabel(\"Episodio\")\n",
    "    plt.ylabel(\"Recompensa Acumulada\")\n",
    "    plt.title(\"Recompensas Acumuladas por Episodio\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función, calcula el próximo estado en el juego de escaleras y serpientes considerando la acción elegida (avanzar o retroceder) y el resultado del dado. Si el estado actual es terminal, retorna el mismo estado. Luego, según la acción, suma o resta el valor del dado. Aplica una lógica de rebote cuando el estado excede los límites del tablero (mayor a 100 o menor a 1), aunque el rebote en el extremo inferior podría mejorarse para mayor precisión. Finalmente, si el nuevo estado corresponde a la base de una escalera o la cabeza de una serpiente, se actualiza automáticamente al estado resultante. La función es sólida, pero convendría revisar y ajustar la lógica del rebote en el extremo inferior para mayor exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularNuevoEstado(s, a, resultadoDado):\n",
    "    if s in estadosTerminales:\n",
    "        return s\n",
    "\n",
    "    if a == \"avanzar\":\n",
    "        nuevoEstado = s + resultadoDado\n",
    "    elif a == \"retroceder\":\n",
    "        nuevoEstado = s - resultadoDado\n",
    "    else:\n",
    "        raise ValueError(\"Acción no válida\")\n",
    "\n",
    "    if nuevoEstado < 1:\n",
    "        nuevoEstado = abs(nuevoEstado) + 1\n",
    "    elif nuevoEstado > 100:\n",
    "        if s == 99 and resultadoDado in [1, 2]:\n",
    "            nuevoEstado = 100\n",
    "        else:\n",
    "            exceso = nuevoEstado - 100\n",
    "            nuevoEstado = 100 - exceso\n",
    "\n",
    "    if nuevoEstado in escaleras:\n",
    "        nuevoEstado = escaleras[nuevoEstado]\n",
    "    if nuevoEstado in serpientes:\n",
    "        nuevoEstado = serpientes[nuevoEstado]\n",
    "\n",
    "    return nuevoEstado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una función que ejecuta 1000 simulaciones del juego, comenzando cada episodio en la casilla 1 y finalizando al llegar a un estado terminal. En cada paso, el agente elige aleatoriamente avanzar o retroceder, lanza un dado cargado para determinar el número de casillas a mover y calcula el nuevo estado considerando las reglas del juego (incluyendo escaleras, serpientes y rebotes). Luego, aplica la ecuación de Bellman en tiempo real para actualizar el valor del estado actual, ponderando las probabilidades del dado y considerando la recompensa obtenida más el valor futuro esperado con un factor de descuento de 0.9. La actualización es una media entre el valor calculado y el valor anterior del estado. La recompensa acumulada de cada episodio se registra en una lista, la cual se retorna al finalizar las simulaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bellmanDP():\n",
    "    recompensasAcumuladas = []\n",
    "    for _ in range(1000):\n",
    "        estado = 1\n",
    "        recompensaAcumulada = 0\n",
    "        while estado not in estadosTerminales:\n",
    "            accion = np.random.choice(acciones)\n",
    "            resultadoDado = np.random.choice([1, 2, 3, 4, 5, 6], p=probabilidades)\n",
    "            nuevoEstado = calcularNuevoEstado(estado, accion, resultadoDado)\n",
    "            recompensa = recompensasEstado[nuevoEstado]\n",
    "\n",
    "            # Ecuación de Bellman\n",
    "            nuevoValor = 0\n",
    "            for accionSimulada in acciones:\n",
    "                for dado, p in zip(range(1, 7), probabilidades):\n",
    "                    siguienteEstado = calcularNuevoEstado(estado, accionSimulada, dado)\n",
    "                    r = recompensasEstado[siguienteEstado]\n",
    "                    nuevoValor += (1 / len(acciones)) * p * (r + gamma * valoresEstado[siguienteEstado])\n",
    "\n",
    "            valoresEstado[estado] = nuevoValor\n",
    "            recompensaAcumulada += recompensa\n",
    "            estado = nuevoEstado\n",
    "\n",
    "        recompensasAcumuladas.append(recompensaAcumulada)\n",
    "    return recompensasAcumuladas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una función, que visualiza los valores finales de cada estado del tablero en formato de matriz 10x10, reflejando la disposición del juego de escaleras y serpientes. Primero, inicializa una matriz de 10x10 con ceros y tipo de dato object para formatear los valores como texto. Luego, recorre cada celda utilizando dos bucles anidados: el índice i determina la fila y j la columna. Para reflejar el patrón en zigzag del tablero (donde las filas pares avanzan de izquierda a derecha y las impares de derecha a izquierda), se usa la condición i % 2 para calcular el número del estado correspondiente. El valor del estado se asigna a la celda correspondiente con formato de dos decimales. Finalmente, la función imprime la matriz, mostrando cada fila con los valores alineados, lo que proporciona una visualización clara de los valores finales de cada casilla del tablero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrarMatrizValores():\n",
    "    matriz = np.zeros((10, 10), dtype=object)\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            estado = i * 10 + (j + 1 if i % 2 == 0 else 10 - j)\n",
    "            matriz[9 - i, j] = f\"{valoresEstado[estado]:7.2f}\"\n",
    "    print(\"\\nMatriz de Valores Finales de los Estados (10x10):\")\n",
    "    for fila in matriz:\n",
    "        print(\" \".join(str(valor) for valor in fila))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ejecuta la simulación parametrizada y generar los datos tabulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Valores Finales de los Estados (10x10):\n",
      "   0.00   -1.77    0.00   -1.08   -8.99    0.00  -18.69  -28.09    0.00  -29.96\n",
      "  -3.57   -0.21    0.00   -8.19  -19.23  -25.58  -28.02  -25.50    0.00  -26.91\n",
      "   0.00   -1.72    3.25    6.26    0.28   -6.89   -8.60    0.00  -22.86  -28.13\n",
      " -27.02    0.00  -28.23    0.00  -33.76    0.00    0.00  -31.09    0.00  -34.20\n",
      " -22.49    0.00  -21.85  -23.13  -23.03    0.00    0.00  -25.11    0.00  -29.02\n",
      " -45.61  -46.57    0.00    0.00    0.00    0.00  -33.00    0.00  -31.49    0.00\n",
      " -44.67  -45.68  -42.45    0.00  -44.58  -46.75  -49.18  -46.23  -43.66  -43.71\n",
      "   0.00  -34.74    0.00  -34.08  -39.29  -44.47  -41.74  -41.44  -42.76  -40.27\n",
      " -38.12  -32.37  -27.06  -28.31  -25.58  -24.50  -26.21  -25.28  -25.55  -26.35\n",
      " -22.60  -23.49  -23.35  -24.21  -25.28  -24.62  -24.10    0.00  -24.43  -25.31\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar simulación con Bellman\n",
    "recompensas = bellmanDP()\n",
    "mostrarGraficoRecompensas(recompensas)\n",
    "mostrarMatrizValores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consideraciones del MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La meta del jugador es ganar la partida llegando a una de las casillas marcadas en azul\n",
    "- El jugardor pierde la partida si cae en una de las casillas marcadas en rojo\n",
    "- En cada jugada, **antes de lanzar el dado**, el jugador dedice si quiere avanzar o retroceder el número de casillas indicadas por lado\n",
    "- El dado está cargado con probalidades **p =[p1,p2,p3,p4,p5,p6]**\n",
    "- En las casillas 1 y 100 la ficha rebota (si se supera el extremo, se avanza en la otra dirección la cantidad restante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Punto 2:_\n",
    "\n",
    "### Modelado del problema como un MDP\n",
    "\n",
    "Modele este problema como un MDP. Detalle todos los elementos del MDP:\n",
    "\n",
    "- **Estados**  \n",
    "- **Recompensas**  \n",
    "- **Acciones**  \n",
    "- **Dinámica de transición**:  \n",
    "  $$ p(s', r \\mid s, a) \\quad \\forall s, s', r, a $$  \n",
    "- **Factor de descuento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos suministrados en el enunciado, se puede colocar podemos definir las variables con las que vamos a trabajar a lo largo del problema. Con estas varibales podemos definir una función que tenga como objetivo modelar el MDP, dando como resultado la transciones y las recompensas asociadas a estas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# informacion inicial que se suministra en el enunciado\n",
    "tamañoTablero = 100\n",
    "gana = {80,100} #el usuario ingresa las celdas azules\n",
    "pierde = {23, 37, 45, 67, 89} #el usuario ingresa la celdas rojas\n",
    "acciones = [-1,1]\n",
    "probabilidades = np.array([0.1, 0.2, 0.3, 0.2, 0.1, 0.1]) #se tiene un dado cargado\n",
    "estados = np.arange(1, tamañoTablero+1) # se configura de esta manera para que vaya desde el 1 al 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar los estados del ejercicio,se implementa un dataframe que indica para cada estado del tablero (1 al 100) si es una casilla de victoria o de derrota, usando las columnas \"Es Terminal Ganar\" y \"Es Terminal Perder\" para marcar con 1 los estados especiales y con 0 el resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado</th>\n",
       "      <th>Es Terminal Ganar</th>\n",
       "      <th>Es Terminal Perder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Estado  Es Terminal Ganar  Es Terminal Perder\n",
       "0        1                  0                   0\n",
       "1        2                  0                   0\n",
       "2        3                  0                   0\n",
       "3        4                  0                   0\n",
       "4        5                  0                   0\n",
       "..     ...                ...                 ...\n",
       "95      96                  0                   0\n",
       "96      97                  0                   0\n",
       "97      98                  0                   0\n",
       "98      99                  0                   0\n",
       "99     100                  1                   0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear un DataFrame con la información del tablero\n",
    "dfEstados = pd.DataFrame({\n",
    "    'Estado': estados,\n",
    "    'Es Terminal Ganar': [1 if s in gana else 0 for s in estados],\n",
    "    'Es Terminal Perder': [1 if s in pierde else 0 for s in estados]\n",
    "})\n",
    "\n",
    "display(dfEstados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una función para estructurar la dinámica del juego como un MDP, generando para cada estado y acción posibles las transiciones a nuevos estados (considerando rebotes, escaleras y serpientes) y sus recompensas. Retorna dos diccionarios: uno con las probabilidades de transición (transicion) y otro con las recompensas esperadas (recompensas).\n",
    "\n",
    "Para definir las condiciones de rebote se tomo la siguiete logica:\n",
    "\n",
    "Si se esta en la casilla 99, y avanzo:\n",
    "\n",
    "- Si el dado saca 1, el resultado es 100 que es estado terminal de victoria.\n",
    "- Si el dado saca 2, el resultado es 100 por la condición de rebote, este estado resultante es termnal de victoria.\n",
    "- Si el dado saca 3, el resultado es la casilla 99\n",
    "- Si el dado saca 4, el resultado es la casilla 98, que dada la serpeinte, lo deja en el estado 28.\n",
    "- Si el dado saca 5, el resultado es la casilla 97\n",
    "- Si el dado saca 6, el resultado es la casilla 96\n",
    "\n",
    "Si se esta en la casilla 1, y decido ir hacia atrás, deberia ocurrir lo siguiente:\n",
    "\n",
    "- Si el dado sale 1, el estado resultante debería ser 1\n",
    "- Si el dado sale 2, el estado resultante debería ser 2\n",
    "- Si el dado sale 3, el estado resultante debería ser 3\n",
    "- Si el dado sale 4, el estado resultante debería ser 4\n",
    "- Si el dado sale 5, el estado resultante debería ser 5\n",
    "- Si el dado sale 6, el estado resultante debería ser 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construirMDP(probabilidades, estados):\n",
    "    transicion = {}\n",
    "    recompensas = {}\n",
    "\n",
    "    for s in estados:\n",
    "        for a in acciones:\n",
    "            transicion[(s, a)] = []\n",
    "            recompensas[(s, a)] = []\n",
    "\n",
    "            for resultadoDado, probabilidad in zip(range(1, 7), probabilidades):\n",
    "                nuevoEstado = s + a * resultadoDado\n",
    "\n",
    "                # Lógica de rebote validada\n",
    "                if nuevoEstado < 1:\n",
    "                    nuevoEstado = abs(nuevoEstado) + 1\n",
    "                elif nuevoEstado > 100:\n",
    "                    if s == 99 and resultadoDado in [1, 2]:\n",
    "                        nuevoEstado = 100\n",
    "                    else:\n",
    "                        exceso = nuevoEstado - 100\n",
    "                        nuevoEstado = 100 - exceso\n",
    "\n",
    "                # Aplicar efecto de serpientes y escaleras\n",
    "                if nuevoEstado in serpientes:\n",
    "                    nuevoEstado = serpientes[nuevoEstado]\n",
    "                elif nuevoEstado in escaleras:\n",
    "                    nuevoEstado = escaleras[nuevoEstado]\n",
    "\n",
    "                # Asignar recompensa según el tipo de casilla\n",
    "                if nuevoEstado in pierde:\n",
    "                    recompensa = -100\n",
    "                elif nuevoEstado in gana:\n",
    "                    recompensa = 100\n",
    "                else:\n",
    "                    recompensa = -1\n",
    "\n",
    "                # Guardar transiciones y recompensas\n",
    "                transicion[(s, a)].append((nuevoEstado, probabilidad))\n",
    "                recompensas[(s, a)].append((probabilidad, recompensa))\n",
    "\n",
    "    return transicion, recompensas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una función que aplica el algoritmo de iteración de valor para calcular la política y los valores óptimos de un MDP. Evalúa cada estado no terminal, calcula el valor esperado de cada acción con la ecuación de Bellman y actualiza el valor del estado con el mejor resultado. Repite este proceso hasta que los cambios sean mínimos, devolviendo la política óptima pi, los valores V y el último delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interacionValor(gana, pierde, transicion, recompensas, estados, acciones, tamaño_tablero, gamma, error=1e-2):\n",
    "    V = np.zeros(tamaño_tablero + 1)\n",
    "    pi = np.zeros(tamaño_tablero + 1)\n",
    "\n",
    "    for s in gana:\n",
    "        V[s] = 100\n",
    "    for s in pierde:\n",
    "        V[s] = -100\n",
    "\n",
    "    delta = 100\n",
    "    while delta >= error:\n",
    "        delta = 0\n",
    "        for s in estados:\n",
    "            if s in gana or s in pierde:\n",
    "                continue\n",
    "\n",
    "            mejorV = -np.inf\n",
    "            mejorAccion = None\n",
    "\n",
    "            for a in acciones:\n",
    "                valor = 0\n",
    "                for (nuevoEstado, probabilidad), (probabilidad_r, recompensa) in zip(transicion[(s, a)], recompensas[(s, a)]):\n",
    "                    contribucion = probabilidad * (recompensa + gamma * V[nuevoEstado])\n",
    "                    valor += contribucion\n",
    "\n",
    "                if valor > mejorV:\n",
    "                    mejorV = valor\n",
    "                    mejorAccion = a\n",
    "\n",
    "            delta = max(delta, abs(V[s] - mejorV))\n",
    "            V[s] = mejorV\n",
    "            pi[s] = mejorAccion\n",
    "\n",
    "    # Construir el DataFrame con los resultados\n",
    "    data = []\n",
    "    for s in estados:\n",
    "        if s not in gana and s not in pierde:\n",
    "            data.append({\n",
    "                'Estado': s,\n",
    "                'Valor de Estado': V[s],\n",
    "                'Mejor Acción': pi[s]\n",
    "            })\n",
    "    dfValoresPolitica = pd.DataFrame(data)\n",
    "\n",
    "    return dfValoresPolitica, pi, V, delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ejecuta la función que define el modelo del MDP, devolviendo dos diccionarios: transicion, que contiene las posibles transiciones y sus probabilidades para cada par (estado, acción), y recompensas, que asigna recompensas esperadas para esas transiciones, considerando escaleras, serpientes, rebotes y las reglas del juego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "transicion, recompensas = construirMDP(probabilidades, estados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza una verificación para evidenciar el contenido del diccionario transicion, el cual almacena todas las posibles transiciones del modelo MDP. Específicamente, para cada par (estado, acción), contiene una lista de tuplas con los posibles estados siguientes y la probabilidad asociada de llegar a ellos, modelando así la dinámica estocástica del entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado</th>\n",
       "      <th>Acción</th>\n",
       "      <th>Siguiente Estado</th>\n",
       "      <th>Probabilidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Estado  Acción  Siguiente Estado  Probabilidad\n",
       "0       1      -1                 1           0.1\n",
       "1       1      -1                 2           0.2\n",
       "2       1      -1                 3           0.3\n",
       "3       1      -1                 4           0.2\n",
       "4       1      -1                 5           0.1\n",
       "5       1      -1                 6           0.1\n",
       "6       1       1                 2           0.1\n",
       "7       1       1                 3           0.2\n",
       "8       1       1                 4           0.3\n",
       "9       1       1                 5           0.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filas = []\n",
    "for (estado, accion), transiciones in transicion.items():\n",
    "    for s_, p in transiciones:\n",
    "        filas.append({'Estado': estado, 'Acción': accion, 'Siguiente Estado': s_, 'Probabilidad': p})\n",
    "\n",
    "dfTransiciones = pd.DataFrame(filas)\n",
    "display(dfTransiciones.head(10))  # Visualiza las primeras 10 filas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza una transforma del diccionario recompensas, en un DataFrame de pandas para visualizarlo en forma tabular; recorre cada (estado, acción) y extrae sus pares (probabilidad, recompensa) en una lista de diccionarios, que luego se convierte en una tabla con columnas 'Estado', 'Acción', 'Probabilidad' y 'Recompensa'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado</th>\n",
       "      <th>Acción</th>\n",
       "      <th>Probabilidad</th>\n",
       "      <th>Recompensa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Estado  Acción  Probabilidad  Recompensa\n",
       "0          1      -1           0.1          -1\n",
       "1          1      -1           0.2          -1\n",
       "2          1      -1           0.3          -1\n",
       "3          1      -1           0.2          -1\n",
       "4          1      -1           0.1          -1\n",
       "...      ...     ...           ...         ...\n",
       "1195     100       1           0.2          -1\n",
       "1196     100       1           0.3          -1\n",
       "1197     100       1           0.2          -1\n",
       "1198     100       1           0.1          -1\n",
       "1199     100       1           0.1          -1\n",
       "\n",
       "[1200 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convertir el diccionario recompensas a una lista de filas\n",
    "filas = []\n",
    "for (estado, accion), lista in recompensas.items():\n",
    "    for probabilidad, recompensa in lista:\n",
    "        filas.append({\n",
    "            'Estado': estado,\n",
    "            'Acción': accion,\n",
    "            'Probabilidad': probabilidad,\n",
    "            'Recompensa': recompensa\n",
    "        })\n",
    "\n",
    "# Crear el DataFrame\n",
    "dfRecompensas = pd.DataFrame(filas)\n",
    "\n",
    "# Mostrar tabla\n",
    "display(dfRecompensas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ejecuta el algoritmo de iteración de valor para obtener la política óptima pi, los valores de estado V y el cambio máximo delta, usando las dinámicas y recompensas del MDP, junto con el factor de descuento y un criterio de convergencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado</th>\n",
       "      <th>Valor de Estado</th>\n",
       "      <th>Mejor Acción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.192451</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.521198</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.085458</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5.121723</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.011175</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>95</td>\n",
       "      <td>60.689744</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>96</td>\n",
       "      <td>72.156480</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>97</td>\n",
       "      <td>91.865163</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>98</td>\n",
       "      <td>79.259254</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>99</td>\n",
       "      <td>79.207513</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Estado  Valor de Estado  Mejor Acción\n",
       "0        1         4.192451           1.0\n",
       "1        2         3.521198           1.0\n",
       "2        3         5.085458           1.0\n",
       "3        4         5.121723           1.0\n",
       "4        5         5.011175           1.0\n",
       "..     ...              ...           ...\n",
       "88      95        60.689744           1.0\n",
       "89      96        72.156480           1.0\n",
       "90      97        91.865163           1.0\n",
       "91      98        79.259254           1.0\n",
       "92      99        79.207513           1.0\n",
       "\n",
       "[93 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfValoresPolitica, pi, V, delta = interacionValor(gana, pierde, transicion, recompensas, estados, acciones, tamañoTablero, gamma, error=1e-3)\n",
    "display(dfValoresPolitica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza una verificación del delta, para permitir verificar si el algoritmo de iteración de valor ha convergido, ya que representa el mayor cambio entre valores de estado en una iteración; el proceso se detiene cuando delta es menor al umbral definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0008840810712769098)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, se muestran los valores estimados de los estados del 1 al 99, omitiendo el estado 0 por no ser parte del tablero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F10</th>\n",
       "      <td>45.670047</td>\n",
       "      <td>40.749245</td>\n",
       "      <td>50.661017</td>\n",
       "      <td>63.506770</td>\n",
       "      <td>60.689744</td>\n",
       "      <td>72.156480</td>\n",
       "      <td>91.865163</td>\n",
       "      <td>79.259254</td>\n",
       "      <td>79.207513</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F9</th>\n",
       "      <td>42.221583</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>71.114445</td>\n",
       "      <td>69.851394</td>\n",
       "      <td>76.447618</td>\n",
       "      <td>84.323679</td>\n",
       "      <td>101.237826</td>\n",
       "      <td>117.809117</td>\n",
       "      <td>106.518431</td>\n",
       "      <td>98.791106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F8</th>\n",
       "      <td>71.807863</td>\n",
       "      <td>82.460825</td>\n",
       "      <td>91.081013</td>\n",
       "      <td>101.527523</td>\n",
       "      <td>98.790996</td>\n",
       "      <td>106.518334</td>\n",
       "      <td>109.449016</td>\n",
       "      <td>101.237753</td>\n",
       "      <td>84.323610</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F7</th>\n",
       "      <td>58.190277</td>\n",
       "      <td>58.210073</td>\n",
       "      <td>52.627503</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>23.904281</td>\n",
       "      <td>29.303675</td>\n",
       "      <td>27.715234</td>\n",
       "      <td>23.525359</td>\n",
       "      <td>18.699092</td>\n",
       "      <td>18.592044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F6</th>\n",
       "      <td>24.831814</td>\n",
       "      <td>22.119118</td>\n",
       "      <td>24.522113</td>\n",
       "      <td>22.068982</td>\n",
       "      <td>22.599363</td>\n",
       "      <td>24.773177</td>\n",
       "      <td>24.831933</td>\n",
       "      <td>24.858260</td>\n",
       "      <td>30.573778</td>\n",
       "      <td>27.697953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5</th>\n",
       "      <td>22.892307</td>\n",
       "      <td>21.608474</td>\n",
       "      <td>25.370302</td>\n",
       "      <td>24.521943</td>\n",
       "      <td>21.379506</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>3.628061</td>\n",
       "      <td>-21.799472</td>\n",
       "      <td>-20.325640</td>\n",
       "      <td>-12.150056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F4</th>\n",
       "      <td>-6.914119</td>\n",
       "      <td>-6.763044</td>\n",
       "      <td>-6.582092</td>\n",
       "      <td>-6.763001</td>\n",
       "      <td>-6.914033</td>\n",
       "      <td>-6.884135</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>5.200065</td>\n",
       "      <td>-4.985344</td>\n",
       "      <td>9.430378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F3</th>\n",
       "      <td>-4.752753</td>\n",
       "      <td>-6.914166</td>\n",
       "      <td>-6.763139</td>\n",
       "      <td>-6.582234</td>\n",
       "      <td>-6.763191</td>\n",
       "      <td>-6.914270</td>\n",
       "      <td>18.930537</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>22.668625</td>\n",
       "      <td>15.320903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>15.189352</td>\n",
       "      <td>16.606837</td>\n",
       "      <td>16.559521</td>\n",
       "      <td>15.533665</td>\n",
       "      <td>22.850698</td>\n",
       "      <td>22.668364</td>\n",
       "      <td>15.189739</td>\n",
       "      <td>18.930378</td>\n",
       "      <td>16.559857</td>\n",
       "      <td>15.533983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>14.719670</td>\n",
       "      <td>13.977527</td>\n",
       "      <td>12.885744</td>\n",
       "      <td>10.600129</td>\n",
       "      <td>8.021276</td>\n",
       "      <td>5.011175</td>\n",
       "      <td>5.121723</td>\n",
       "      <td>5.085458</td>\n",
       "      <td>3.521198</td>\n",
       "      <td>4.192451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            C1          C2         C3          C4         C5          C6  \\\n",
       "F10  45.670047   40.749245  50.661017   63.506770  60.689744   72.156480   \n",
       "F9   42.221583 -100.000000  71.114445   69.851394  76.447618   84.323679   \n",
       "F8   71.807863   82.460825  91.081013  101.527523  98.790996  106.518334   \n",
       "F7   58.190277   58.210073  52.627503 -100.000000  23.904281   29.303675   \n",
       "F6   24.831814   22.119118  24.522113   22.068982  22.599363   24.773177   \n",
       "F5   22.892307   21.608474  25.370302   24.521943  21.379506 -100.000000   \n",
       "F4   -6.914119   -6.763044  -6.582092   -6.763001  -6.914033   -6.884135   \n",
       "F3   -4.752753   -6.914166  -6.763139   -6.582234  -6.763191   -6.914270   \n",
       "F2   15.189352   16.606837  16.559521   15.533665  22.850698   22.668364   \n",
       "F1   14.719670   13.977527  12.885744   10.600129   8.021276    5.011175   \n",
       "\n",
       "             C7          C8          C9         C10  \n",
       "F10   91.865163   79.259254   79.207513  100.000000  \n",
       "F9   101.237826  117.809117  106.518431   98.791106  \n",
       "F8   109.449016  101.237753   84.323610  100.000000  \n",
       "F7    27.715234   23.525359   18.699092   18.592044  \n",
       "F6    24.831933   24.858260   30.573778   27.697953  \n",
       "F5     3.628061  -21.799472  -20.325640  -12.150056  \n",
       "F4  -100.000000    5.200065   -4.985344    9.430378  \n",
       "F3    18.930537 -100.000000   22.668625   15.320903  \n",
       "F2    15.189739   18.930378   16.559857   15.533983  \n",
       "F1     5.121723    5.085458    3.521198    4.192451  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convertir V[1:101] a una matriz 10x10 con el orden tipo serpenteo (zigzag)\n",
    "valoresTablero = V[1:101].reshape(10, 10)\n",
    "\n",
    "valoresTablero = np.flipud(valoresTablero)\n",
    "\n",
    "for i in range(10):\n",
    "    if i % 2 == 1:\n",
    "        valoresTablero[i] = valoresTablero[i][::-1]\n",
    "\n",
    "dfValores = pd.DataFrame(valoresTablero, columns=[f\"C{j+1}\" for j in range(10)], index=[f\"F{10-i}\" for i in range(10)])\n",
    "display(dfValores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F9</th>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>0.0</td>\n",
       "      <td>⬅️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F7</th>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>0.0</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F6</th>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5</th>\n",
       "      <td>➡️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>0.0</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F4</th>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>0.0</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F3</th>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>0.0</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>⬅️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C1  C2   C3   C4   C5  C6   C7  C8   C9 C10\n",
       "F10  0.0  ➡️   ➡️   ➡️   ➡️  ➡️   ➡️  ➡️   ➡️  ➡️\n",
       "F9    ⬅️  ⬅️   ⬅️   ⬅️   ⬅️  ⬅️   ⬅️  ⬅️  0.0  ⬅️\n",
       "F8   0.0  ➡️   ➡️   ➡️   ➡️  ➡️   ➡️  ➡️   ➡️  ➡️\n",
       "F7    ⬅️  ⬅️   ⬅️   ⬅️   ⬅️  ⬅️  0.0  ➡️   ➡️  ➡️\n",
       "F6    ➡️  ➡️   ➡️   ⬅️   ⬅️  ⬅️   ⬅️  ⬅️   ➡️  ➡️\n",
       "F5    ➡️  ⬅️   ⬅️   ⬅️  0.0  ➡️   ➡️  ➡️   ➡️  ➡️\n",
       "F4    ➡️  ➡️   ➡️  0.0   ⬅️  ⬅️   ⬅️  ⬅️   ⬅️  ⬅️\n",
       "F3    ⬅️  ⬅️  0.0   ⬅️   ➡️  ➡️   ➡️  ➡️   ➡️  ⬅️\n",
       "F2    ⬅️  ⬅️   ➡️   ⬅️   ➡️  ➡️   ➡️  ➡️   ➡️  ➡️\n",
       "F1    ➡️  ➡️   ➡️   ➡️   ➡️  ➡️   ➡️  ➡️   ➡️  ➡️"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear una matriz vacía de 10x10 para la política\n",
    "politicaTablero = np.zeros((10, 10), dtype=object)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        estado = i * 10 + (j + 1 if i % 2 == 0 else 10 - j)\n",
    "        politicaTablero[9 - i, j] = pi[estado]\n",
    "\n",
    "politicaTablero = np.where(politicaTablero == -1, \"⬅️\", politicaTablero)\n",
    "politicaTablero = np.where(politicaTablero == 1, \"➡️\", politicaTablero)\n",
    "dfPolitica = pd.DataFrame(politicaTablero, columns=[f\"C{j+1}\" for j in range(10)], index=[f\"F{10-i}\" for i in range(10)])\n",
    "display(dfPolitica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacion Monte Carlo Off-Policy\n",
    "\n",
    "En este caso se empieza creando una funcion que simule los eventos de la politica b que es soft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa una función que crea una política probabilística donde a cada estado se le asigna una probabilidad aleatoria de tomar la acción -1 o 1, asegurando que ambas sumen 1. Esto permite simular decisiones no deterministas útiles en algoritmos como Monte Carlo off-policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se genera la politica soft \"asigna probabilidades a todos los estados\"\n",
    "def politicaSoft(estados, escaleras, serpientes, gana, pierde):\n",
    "    piB = {}\n",
    "    ya_definidos = set()\n",
    "\n",
    "    # Paso 1: recorrer estados y generar política aleatoria solo si aún no está definida\n",
    "    for s in estados:\n",
    "        if s in gana or s in pierde:\n",
    "            continue\n",
    "\n",
    "        if s in piB:\n",
    "            continue  # ya definido por sincronización previa\n",
    "\n",
    "        # Crear política aleatoria\n",
    "        p = np.random.uniform(0.01, 0.99)\n",
    "        politica = {-1: p, 1: 1 - p}\n",
    "        piB[s] = politica\n",
    "        ya_definidos.add(s)\n",
    "\n",
    "        # Sincronización con escalera (destino hereda de origen)\n",
    "        if s in escaleras:\n",
    "            destino = escaleras[s]\n",
    "            if destino not in gana and destino not in pierde:\n",
    "                piB[destino] = politica\n",
    "                ya_definidos.add(destino)\n",
    "\n",
    "        # Sincronización con serpiente (origen y destino comparten política)\n",
    "        if s in serpientes:\n",
    "            destino = serpientes[s]\n",
    "            if destino not in gana and destino not in pierde:\n",
    "                piB[destino] = politica\n",
    "                piB[s] = politica  # redundante, pero asegura simetría\n",
    "                ya_definidos.add(destino)\n",
    "\n",
    "    return piB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función accion_soft(estado, pi_b) selecciona aleatoriamente una acción para un estado dado, según las probabilidades definidas por la política pi_b. Extrae las acciones posibles y sus respectivas probabilidades del estado actual, luego utiliza np.random.choice para elegir una acción de forma probabilística, permitiendo así decisiones estocásticas durante la simulación del agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en la simulacion se debe elegir una accion en cada estado\n",
    "def accionSoft(estado, piB):\n",
    "\n",
    "  accionesConProbabilidades = piB[estado]\n",
    "\n",
    "  listaAcciones = []\n",
    "  listaProbabilidad = []\n",
    "\n",
    "  for accion, prob in accionesConProbabilidades.items(): #toma una accion al azar pero teniendo en cuenta las probabilidad en las que pueden ocurrir\n",
    "    listaAcciones.append(accion)\n",
    "    listaProbabilidad.append(prob)   \n",
    "\n",
    "  accionElegida = np.random.choice(listaAcciones, p = listaProbabilidad)\n",
    "\n",
    "  return accionElegida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa una función que simula la transición de un agente en el tablero del juego dadas una acción (avanzar o retroceder), el resultado del dado, y la posición actual. Calcula el nuevo estado aplicando la acción y el dado, ajusta si hay rebotes en los extremos del tablero (por encima de 100 o por debajo de 1), y considera los efectos de escaleras y serpientes. Luego asigna la recompensa correspondiente: +100 si se alcanza un estado de victoria, -100 si se alcanza uno de pérdida, o -1 en cualquier otro caso. Finalmente, retorna el nuevo estado y la recompensa obtenida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teniendo la politica y que se hace en cada estado toca definir en el ambiente las transiciones\n",
    "def transicionRecompensaMontecarlo(estado, accion, dado, tamañoTablero, escalera, serpientes):\n",
    "  nuevoEstado = estado + (accion*dado)\n",
    "  # ajuste para condiciones de borde y cambios de estado por escalera y serpientes\n",
    "  if nuevoEstado > 100:\n",
    "    nuevoEstado = 100 - (nuevoEstado-100)\n",
    "  elif nuevoEstado == 0:\n",
    "    nuevoEstado = 1 + (nuevoEstado + 1)\n",
    "  elif nuevoEstado <= -1:\n",
    "    nuevoEstado = 1 - (nuevoEstado -1)\n",
    "\n",
    "  if nuevoEstado in serpientes:\n",
    "    nuevoEstado = serpientes[nuevoEstado]\n",
    "  elif nuevoEstado in escalera:\n",
    "    nuevoEstado = escalera[nuevoEstado]\n",
    "\n",
    "  # ajuste de las nuevas recompensas por los cambios de estado\n",
    "  recompensa = 0\n",
    "\n",
    "  if nuevoEstado in pierde:\n",
    "    recompensa = -100\n",
    "  elif nuevoEstado in gana:\n",
    "    recompensa = 100\n",
    "  else:\n",
    "    recompensa = -1\n",
    "\n",
    "  return nuevoEstado, recompensa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se implementa una función que simula un episodio completo del juego \"escaleras y serpientes\" bajo una política de comportamiento pi_b. Inicia en la casilla 1 y, en cada paso, elige una acción probabilística (avanzar o retroceder), lanza un dado con las probabilidades dadas y calcula el nuevo estado y la recompensa correspondiente (teniendo en cuenta rebotes, escaleras y serpientes). Registra cada transición en una lista episodio, y la simulación continúa hasta alcanzar un estado terminal (de victoria o derrota). Finalmente, retorna la secuencia completa del episodio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ya con estas funciones podemos crear la simulacion de un episodio bajo la politica que definamos\n",
    "def sumulacion(pi_b, tamañoTablero, escaleras, serpientes, gana, pierde, probabilidades):\n",
    "\n",
    "  episodio = []\n",
    "  estado = 1 #esto lo puede cambiar la persona para definir desde donde empieza la partida para nuestro caso arracamos desde la casilla 1\n",
    "\n",
    "  while estado not in gana and estado not in pierde:\n",
    "    accion = accionSoft(estado, pi_b)\n",
    "    dado = np.random.choice(np.arange(1,7), p = probabilidades)\n",
    "    nuevoEstado, recompensa = transicionRecompensaMontecarlo(estado, accion, dado, tamañoTablero, escaleras, serpientes)\n",
    "\n",
    "    episodio.append((estado, accion, recompensa))\n",
    "    estado = nuevoEstado\n",
    "\n",
    "  return episodio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se prueba que las funciones trabajen correctamente: \n",
    "\n",
    "1. Se genera una política soft (pi_b)\n",
    "2. Se elige una acción en el estado 1 según esa política\n",
    "3. Se calcula el nuevo estado y la recompensa al moverse desde el estado 1 con un dado que saca 3, considerando rebotes, escaleras y serpientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    " # esta celda es de pruebas para ver que cada funcicion cumpliera con su parte\n",
    "piB = politicaSoft(estados, escaleras, serpientes, gana, pierde)\n",
    "accion = accionSoft(1, piB)\n",
    "nuevoEstadoRecompensa = transicionRecompensaMontecarlo(1, accion, 3, tamañoTablero, escaleras, serpientes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable pi_b representa la política de comportamiento (behavior policy) generada mediante una estrategia soft, es decir, asigna probabilidades aleatorias a cada acción (-1 para retroceder y 1 para avanzar) en todos los estados del tablero. Su estructura es un diccionario donde la clave es el número del estado y el valor es otro diccionario con las acciones posibles y sus respectivas probabilidades. Esta política se usa para simular episodios en el algoritmo de Monte Carlo off-policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado</th>\n",
       "      <th>Prob_avanzar (1)</th>\n",
       "      <th>Prob_retroceder (-1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.727675</td>\n",
       "      <td>0.272325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.239693</td>\n",
       "      <td>0.760307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.228108</td>\n",
       "      <td>0.771892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.812150</td>\n",
       "      <td>0.187850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.197569</td>\n",
       "      <td>0.802431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>95</td>\n",
       "      <td>0.270909</td>\n",
       "      <td>0.729091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>96</td>\n",
       "      <td>0.410732</td>\n",
       "      <td>0.589268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>97</td>\n",
       "      <td>0.546838</td>\n",
       "      <td>0.453162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>98</td>\n",
       "      <td>0.718304</td>\n",
       "      <td>0.281696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>99</td>\n",
       "      <td>0.081427</td>\n",
       "      <td>0.918573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Estado  Prob_avanzar (1)  Prob_retroceder (-1)\n",
       "0        1          0.727675              0.272325\n",
       "1        2          0.239693              0.760307\n",
       "2        3          0.228108              0.771892\n",
       "3        4          0.812150              0.187850\n",
       "4        5          0.197569              0.802431\n",
       "..     ...               ...                   ...\n",
       "88      95          0.270909              0.729091\n",
       "89      96          0.410732              0.589268\n",
       "90      97          0.546838              0.453162\n",
       "91      98          0.718304              0.281696\n",
       "92      99          0.081427              0.918573\n",
       "\n",
       "[93 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convertir pi_b a un DataFrame para mejor visualización\n",
    "df_piB = pd.DataFrame([\n",
    "    {'Estado': estado, 'Prob_avanzar (1)': probs[1], 'Prob_retroceder (-1)': probs[-1]}\n",
    "    for estado, probs in piB.items()\n",
    "])\n",
    "\n",
    "# Mostrar el DataFrame ordenado por estado\n",
    "df_piB = df_piB.sort_values(by='Estado').reset_index(drop=True)\n",
    "display(df_piB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se imprime el resultado de una jugada simulada, mostrando la acción tomada y el nuevo estado con su recompensa correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La accion que tomas es  1 \n",
      " En este caso se lee lee como que el nuevo estado es 4 y en este estado tiene una recompensa de -1  (np.int64(4), -1)\n"
     ]
    }
   ],
   "source": [
    "print(\"La accion que tomas es \", accion, \"\\n\", \"En este caso se lee lee como que el nuevo estado es 4 y en este estado tiene una recompensa de -1 \",nuevoEstadoRecompensa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se ejecuta una simulación del juego desde el estado 1 hasta un estado terminal, siguiendo una política soft y registrando cada paso como (estado, acción, recompensa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado</th>\n",
       "      <th>Acción</th>\n",
       "      <th>Recompensa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Estado  Acción  Recompensa\n",
       "0       1       1          -1\n",
       "1       6       1          -1\n",
       "2       9       1          -1\n",
       "3      12      -1          -1\n",
       "4      26      -1          -1\n",
       "5      24       1          -1\n",
       "6      26      -1        -100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejecutar la simulación\n",
    "episodio = sumulacion(piB, tamañoTablero, escaleras, serpientes, gana, pierde, probabilidades)\n",
    "dfEpisodio = pd.DataFrame(episodio, columns=[\"Estado\", \"Acción\", \"Recompensa\"])\n",
    "display(dfEpisodio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se creado el ambiente para crear simulaciones, se tiene el insumo necesario para realizar el algoritmo de Monte-Carlo Off-Policy.\n",
    "\n",
    "Se implementa una función que aplica el algoritmo de control de Monte Carlo off-policy con promedio ponderado para encontrar una política óptima, simulando episodios bajo una política de comportamiento aleatoria y actualizando los valores Q(s, a) con pesos de importancia. Al final, retorna la política óptima y la tabla de valores Q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montecarloOffPolicy(episodios, estados, escaleras, serpientes, probabilidades, gamma):\n",
    "\n",
    "  Q = defaultdict(lambda: {a: 0.0 for a in [-1, 1]}) #tabla de valores de Q(s,a)\n",
    "  C = defaultdict(lambda: {a: 0.0 for a in [-1, 1]}) #tabla de los pesos de W\n",
    "\n",
    "  piB = politicaSoft(estados,escaleras, serpientes, gana, pierde)\n",
    "\n",
    "  for i in range(episodios):\n",
    "    #se simula los episodios con als funciones que se crearon previamente\n",
    "\n",
    "    episodio = sumulacion(piB, tamañoTablero, escaleras, serpientes, gana, pierde, probabilidades)\n",
    "\n",
    "    G = 0 # se inicializa el retorno\n",
    "    W = 1 # encaso de que se visite se le da un peso de 1 para que se tenga en cuenta\n",
    "\n",
    "    #se crea la politica objetivo\n",
    "    politicaObjetivo = {}\n",
    "    for s in estados:\n",
    "      if s in gana or s in pierde:\n",
    "        politicaObjetivo[s] = 0\n",
    "        continue\n",
    "\n",
    "      acciones = Q[s]\n",
    "      mejorAccion = None\n",
    "      mejorValor = -100000\n",
    "\n",
    "      for a in acciones:\n",
    "\n",
    "        for a in acciones:\n",
    "          if acciones[a] > mejorValor:\n",
    "\n",
    "            mejorValor = acciones[a]\n",
    "            mejorAccion = a\n",
    "\n",
    "        politicaObjetivo[s] = mejorAccion\n",
    "\n",
    "    #ahora se recorre el episodio en sentido contrario\n",
    "    for s, a, r in reversed(episodio):\n",
    "\n",
    "      G = r + gamma * G # se actualiza\n",
    "      C[s][a] += W # Acumulo peso para promedio pesado\n",
    "\n",
    "      #actualizo Q con el promedio pesado\n",
    "      Q[s][a] += (W/C[s][a]) * (G-Q[s][a])\n",
    "\n",
    "      # cuando un estado accion no se encuentra no sigue\n",
    "      if a != politicaObjetivo.get(s, a):\n",
    "        break\n",
    "\n",
    "      #ahora se actualizan los pesos de los que si se encontraton\n",
    "      probObjetivo = 1\n",
    "      probComportamiento = piB[s][a]\n",
    "      W *= probObjetivo/probComportamiento\n",
    "\n",
    "      if W == 0:\n",
    "        break\n",
    "  politicaOptima = {}\n",
    "\n",
    "  for s in estados:\n",
    "    if s in gana or s in pierde:\n",
    "      politicaOptima[s] = 0\n",
    "      continue\n",
    "      \n",
    "    acciones = Q[s]\n",
    "    mejorAccion = None\n",
    "    mejorValor = -100000\n",
    "    for a in acciones:\n",
    "      if acciones[a] > mejorValor:\n",
    "\n",
    "        mejorValor = acciones[a]\n",
    "        mejorAccion = a\n",
    "\n",
    "    politicaOptima[s] = mejorAccion\n",
    "\n",
    "  return politicaOptima, Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se ejecuta el algoritmo Monte Carlo Off-Policy por 2 episodios, generando una política óptima (politica_optima) y los valores Q(s, a), y luego muestra la política aprendida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado</th>\n",
       "      <th>Mejor Acción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Estado  Mejor Acción\n",
       "0        1             1\n",
       "1        2             1\n",
       "2        3            -1\n",
       "3        4             1\n",
       "4        5            -1\n",
       "..     ...           ...\n",
       "95      96             1\n",
       "96      97             1\n",
       "97      98            -1\n",
       "98      99            -1\n",
       "99     100             0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejecutar Monte Carlo Off-Policy\n",
    "politicaOptima, Q = montecarloOffPolicy(1000, estados, escaleras, serpientes, probabilidades, gamma)\n",
    "dfPoliticaOptima = pd.DataFrame(list(politicaOptima.items()), columns=['Estado', 'Mejor Acción'])\n",
    "display(dfPoliticaOptima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una función que compara, para cada estado, la acción sugerida por una política $\\pi$ con la mejor acción de acuerdo con los valores de $Q(s, a)$. Retorna un dataframe que muestra, para cada estado, la acción de la política, la acción óptima según $Q$, y una indicación booleana sobre si coinciden. Esta función es útil para validar si una política aprendida toma decisiones óptimas en todos los estados, según la función de valor-acción $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificarOptimalidadPolitica(pi, Q, estados):\n",
    "    resultados = []\n",
    "\n",
    "    for s in estados:\n",
    "        accionesQ = Q[s]\n",
    "        accionOptimaQ = max(accionesQ, key=accionesQ.get)\n",
    "        accionPi = pi.get(s) if isinstance(pi, dict) else pi[s]\n",
    "\n",
    "        resultados.append({\n",
    "            'Estado': s,\n",
    "            'Acción política': accionPi,\n",
    "            'Acción óptima según Q': accionOptimaQ,\n",
    "            '¿Es óptima?': accionPi == accionOptimaQ\n",
    "        })\n",
    "\n",
    "    dfComparacion = pd.DataFrame(resultados)\n",
    "    esOptima = dfComparacion['¿Es óptima?'].all()\n",
    "\n",
    "    return dfComparacion, esOptima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas líneas verifican si la política aprendida es óptima comparando, estado por estado, la acción sugerida por la política con la mejor acción según los valores \\( Q(s, a) \\).  \n",
    "Se muestra un DataFrame con los resultados de esta comparación y un valor booleano que indica si la política es óptima en todos los estados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado</th>\n",
       "      <th>Acción política</th>\n",
       "      <th>Acción óptima según Q</th>\n",
       "      <th>¿Es óptima?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Estado  Acción política  Acción óptima según Q  ¿Es óptima?\n",
       "0        1                1                      1         True\n",
       "1        2                1                      1         True\n",
       "2        3               -1                     -1         True\n",
       "3        4                1                      1         True\n",
       "4        5               -1                     -1         True\n",
       "..     ...              ...                    ...          ...\n",
       "95      96                1                      1         True\n",
       "96      97                1                      1         True\n",
       "97      98               -1                     -1         True\n",
       "98      99               -1                     -1         True\n",
       "99     100                0                     -1        False\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿La política es óptima? False\n"
     ]
    }
   ],
   "source": [
    "dfCheck, esOptima = verificarOptimalidadPolitica(politicaOptima, Q, estados)\n",
    "display(dfCheck)\n",
    "print(\"¿La política es óptima?\", esOptima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se define un metodo para exportar la política a un DataFrame, que se gaurdará a un archivo .csv que podrá leerse en la implementación del taller # 3, como política de comportamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportarPoliticaSoft(piB, nombre_archivo=\"politica_soft.csv\", gana=set(), pierde=set()):\n",
    "    terminales = gana.union(pierde)\n",
    "    filas = []\n",
    "    for estado, acciones in piB.items():\n",
    "        if estado in terminales:\n",
    "            continue  # ignorar terminales\n",
    "        fila = {\n",
    "            \"Estado\": estado,\n",
    "            \"Prob_-1\": acciones.get(-1, 0.0),\n",
    "            \"Prob_1\": acciones.get(1, 0.0)\n",
    "        }\n",
    "        filas.append(fila)\n",
    "\n",
    "    # Crear y ordenar DataFrame por Estado\n",
    "    df = pd.DataFrame(filas)\n",
    "    df = df.sort_values(by=\"Estado\").reset_index(drop=True)\n",
    "\n",
    "    df.to_csv(nombre_archivo, index=False)\n",
    "    print(f\"Política soft exportada ordenada por estado a {nombre_archivo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se exporta la politica soft de comportamiento, al archivo .csv acuerdo el metodo definido anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Política soft exportada ordenada por estado a politica_soft.csv\n"
     ]
    }
   ],
   "source": [
    "exportarPoliticaSoft(piB, nombre_archivo=\"politica_soft.csv\", gana=gana, pierde=pierde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Punto 3:_\n",
    "\n",
    "Genere un dado aleatorio p y cree un MDP con este dado, las casillas azules mostradas en la figura y las casillas rojas ubicadas en una posición aleatoria en una ventana de ±2 casillas con respecto a las posiciones mostradas en la figura.\n",
    "\n",
    "Para este caso los estados terminales no son fijos y cambian de manera aleatoria, para esto se toma como variables de entrada la ventana de ±2 casillas y junto con los estados terminales de rojo y azul y se seleccionan de manera aleatoria los nuevos estados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# informacion inicial que se suministra en el enunciado\n",
    "tamañoTablero = 100\n",
    "gana = {80,100} #el usuario ingresa las celdas azules\n",
    "pierde = {23, 37, 45, 67, 89} #el usuario ingresa la celdas rojas\n",
    "acciones = [-1,1]\n",
    "probabilidades = np.random.dirichlet(np.ones(6)) #se tiene un dado con probabilidades uniformes\n",
    "estados = np.arange(1, tamañoTablero+1) # se configura de esta manera para que vaya desde el 1 al 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "desplazamiento = 2 #si la ventana de casillas cambia el usuario puede modificar en esta celda\n",
    "\n",
    "nuevoEstadosGana = set()\n",
    "nuevosEstadosPierde = set()\n",
    "\n",
    "for i in gana:\n",
    "    ventana = list(range(i - desplazamiento, i + desplazamiento))\n",
    "    ventana = [c for c in ventana if 1 <= c <= 100]\n",
    "    nuevaCeldaGana = np.random.choice(ventana)\n",
    "    \n",
    "    nuevoEstadosGana.add(nuevaCeldaGana)\n",
    "\n",
    "\n",
    "for i in pierde:\n",
    "    ventana = list(range(i - desplazamiento, i + desplazamiento))\n",
    "    ventana = [c for c in ventana if 1 <= c <= 100]\n",
    "    nuevaCeldaPierde = np.random.choice(ventana)\n",
    "    \n",
    "    nuevosEstadosPierde.add(nuevaCeldaPierde)\n",
    "\n",
    "gana = nuevoEstadosGana # Como las funciones usan internamente los estados terminales se vuelven a renombrar las variables para que hagan uso de estos nuevos estados terminales\n",
    "pierde = nuevosEstadosPierde # Como las funciones usan internamente los estados terminales se vuelven a renombrar las variables para que hagan uso de estos nuevos estados terminales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{79, 98}"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **a)** Halle una política óptima usando iteración de valor. Chequee la optimalidad de esta política.\n",
    "\n",
    "Como ya tenemos los nuevos estados terminales podemos definir el **MDP** y se usa todo lo desarrollado en el **punto 2** para definir la politica optima con el algoritmo de **iteracion de valor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "transicion, recompensas  = construirMDP(probabilidades, estados)\n",
    "\n",
    "filas = []\n",
    "for (estado, accion), transiciones in transicion.items():\n",
    "    for s_, p in transiciones:\n",
    "        filas.append({'Estado': estado, 'Acción': accion, 'Siguiente Estado': s_, 'Probabilidad': p})\n",
    "\n",
    "dfTransiciones = pd.DataFrame(filas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado</th>\n",
       "      <th>Acción</th>\n",
       "      <th>Probabilidad</th>\n",
       "      <th>Recompensa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.014805</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.300178</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.012921</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.296192</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300178</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012921</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.296192</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.296772</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Estado  Acción  Probabilidad  Recompensa\n",
       "0          1      -1      0.014805          -1\n",
       "1          1      -1      0.300178          -1\n",
       "2          1      -1      0.079133          -1\n",
       "3          1      -1      0.012921          -1\n",
       "4          1      -1      0.296192          -1\n",
       "...      ...     ...           ...         ...\n",
       "1195     100       1      0.300178          -1\n",
       "1196     100       1      0.079133          -1\n",
       "1197     100       1      0.012921          -1\n",
       "1198     100       1      0.296192          -1\n",
       "1199     100       1      0.296772          -1\n",
       "\n",
       "[1200 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convertir el diccionario recompensas a una lista de filas\n",
    "filas = []\n",
    "for (estado, accion), lista in recompensas.items():\n",
    "    for probabilidad, recompensa in lista:\n",
    "        filas.append({\n",
    "            'Estado': estado,\n",
    "            'Acción': accion,\n",
    "            'Probabilidad': probabilidad,\n",
    "            'Recompensa': recompensa\n",
    "        })\n",
    "\n",
    "# Crear el DataFrame\n",
    "dfRecompensas = pd.DataFrame(filas)\n",
    "\n",
    "# Mostrar tabla\n",
    "display(dfRecompensas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado</th>\n",
       "      <th>Valor de Estado</th>\n",
       "      <th>Mejor Acción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>29.157351</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>32.366508</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>33.544321</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>31.515388</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>32.288567</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>95</td>\n",
       "      <td>39.570248</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>96</td>\n",
       "      <td>47.053685</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>97</td>\n",
       "      <td>41.377979</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>99</td>\n",
       "      <td>35.873461</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>100</td>\n",
       "      <td>36.083187</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Estado  Valor de Estado  Mejor Acción\n",
       "0        1        29.157351           1.0\n",
       "1        2        32.366508           1.0\n",
       "2        3        33.544321           1.0\n",
       "3        4        31.515388           1.0\n",
       "4        5        32.288567           1.0\n",
       "..     ...              ...           ...\n",
       "88      95        39.570248          -1.0\n",
       "89      96        47.053685          -1.0\n",
       "90      97        41.377979          -1.0\n",
       "91      99        35.873461           1.0\n",
       "92     100        36.083187          -1.0\n",
       "\n",
       "[93 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfValoresPolitica, piPunto3a, V, delta = interacionValor(gana, pierde, transicion, recompensas, estados, acciones, tamañoTablero, gamma, error=1e-3)\n",
    "display(dfValoresPolitica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F10</th>\n",
       "      <td>63.425475</td>\n",
       "      <td>36.238116</td>\n",
       "      <td>34.389027</td>\n",
       "      <td>43.901869</td>\n",
       "      <td>39.570248</td>\n",
       "      <td>47.053685</td>\n",
       "      <td>41.377979</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.873461</td>\n",
       "      <td>36.083187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F9</th>\n",
       "      <td>59.325720</td>\n",
       "      <td>42.620004</td>\n",
       "      <td>65.181134</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>86.698309</td>\n",
       "      <td>100.373284</td>\n",
       "      <td>109.847215</td>\n",
       "      <td>86.191765</td>\n",
       "      <td>90.526587</td>\n",
       "      <td>111.690739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F8</th>\n",
       "      <td>68.377026</td>\n",
       "      <td>84.259591</td>\n",
       "      <td>108.733756</td>\n",
       "      <td>111.815164</td>\n",
       "      <td>87.743370</td>\n",
       "      <td>90.870694</td>\n",
       "      <td>101.723758</td>\n",
       "      <td>75.781155</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>83.857407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F7</th>\n",
       "      <td>73.712367</td>\n",
       "      <td>78.037338</td>\n",
       "      <td>62.878608</td>\n",
       "      <td>45.808664</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>51.384767</td>\n",
       "      <td>33.759780</td>\n",
       "      <td>27.952142</td>\n",
       "      <td>37.972987</td>\n",
       "      <td>31.815723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F6</th>\n",
       "      <td>38.739207</td>\n",
       "      <td>39.834823</td>\n",
       "      <td>35.190414</td>\n",
       "      <td>36.001786</td>\n",
       "      <td>42.418887</td>\n",
       "      <td>38.931937</td>\n",
       "      <td>32.529092</td>\n",
       "      <td>31.993967</td>\n",
       "      <td>33.646116</td>\n",
       "      <td>28.833220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5</th>\n",
       "      <td>36.313078</td>\n",
       "      <td>50.343594</td>\n",
       "      <td>48.733153</td>\n",
       "      <td>39.604960</td>\n",
       "      <td>41.160726</td>\n",
       "      <td>51.197271</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>39.090984</td>\n",
       "      <td>34.739303</td>\n",
       "      <td>49.424165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F4</th>\n",
       "      <td>37.198258</td>\n",
       "      <td>38.195034</td>\n",
       "      <td>35.819368</td>\n",
       "      <td>34.031608</td>\n",
       "      <td>32.476921</td>\n",
       "      <td>31.008840</td>\n",
       "      <td>46.873152</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>40.305243</td>\n",
       "      <td>39.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F3</th>\n",
       "      <td>35.458913</td>\n",
       "      <td>40.215452</td>\n",
       "      <td>39.138332</td>\n",
       "      <td>48.053109</td>\n",
       "      <td>48.637827</td>\n",
       "      <td>39.497060</td>\n",
       "      <td>40.557548</td>\n",
       "      <td>48.586267</td>\n",
       "      <td>37.895509</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>37.197401</td>\n",
       "      <td>35.458112</td>\n",
       "      <td>40.214811</td>\n",
       "      <td>39.137776</td>\n",
       "      <td>48.052672</td>\n",
       "      <td>48.637500</td>\n",
       "      <td>39.496731</td>\n",
       "      <td>40.557284</td>\n",
       "      <td>48.586201</td>\n",
       "      <td>37.895403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>38.194079</td>\n",
       "      <td>35.818289</td>\n",
       "      <td>34.030410</td>\n",
       "      <td>32.670216</td>\n",
       "      <td>34.956407</td>\n",
       "      <td>32.288567</td>\n",
       "      <td>31.515388</td>\n",
       "      <td>33.544321</td>\n",
       "      <td>32.366508</td>\n",
       "      <td>29.157351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            C1         C2          C3          C4          C5          C6  \\\n",
       "F10  63.425475  36.238116   34.389027   43.901869   39.570248   47.053685   \n",
       "F9   59.325720  42.620004   65.181134 -100.000000   86.698309  100.373284   \n",
       "F8   68.377026  84.259591  108.733756  111.815164   87.743370   90.870694   \n",
       "F7   73.712367  78.037338   62.878608   45.808664 -100.000000   51.384767   \n",
       "F6   38.739207  39.834823   35.190414   36.001786   42.418887   38.931937   \n",
       "F5   36.313078  50.343594   48.733153   39.604960   41.160726   51.197271   \n",
       "F4   37.198258  38.195034   35.819368   34.031608   32.476921   31.008840   \n",
       "F3   35.458913  40.215452   39.138332   48.053109   48.637827   39.497060   \n",
       "F2   37.197401  35.458112   40.214811   39.137776   48.052672   48.637500   \n",
       "F1   38.194079  35.818289   34.030410   32.670216   34.956407   32.288567   \n",
       "\n",
       "             C7          C8          C9         C10  \n",
       "F10   41.377979  100.000000   35.873461   36.083187  \n",
       "F9   109.847215   86.191765   90.526587  111.690739  \n",
       "F8   101.723758   75.781155  100.000000   83.857407  \n",
       "F7    33.759780   27.952142   37.972987   31.815723  \n",
       "F6    32.529092   31.993967   33.646116   28.833220  \n",
       "F5  -100.000000   39.090984   34.739303   49.424165  \n",
       "F4    46.873152 -100.000000   40.305243   39.000741  \n",
       "F3    40.557548   48.586267   37.895509 -100.000000  \n",
       "F2    39.496731   40.557284   48.586201   37.895403  \n",
       "F1    31.515388   33.544321   32.366508   29.157351  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convertir V[1:101] a una matriz 10x10 con el orden tipo serpenteo (zigzag)\n",
    "valoresTablero = V[1:101].reshape(10, 10)\n",
    "\n",
    "valoresTablero = np.flipud(valoresTablero)\n",
    "\n",
    "for i in range(10):\n",
    "    if i % 2 == 1:\n",
    "        valoresTablero[i] = valoresTablero[i][::-1]\n",
    "\n",
    "dfValores = pd.DataFrame(valoresTablero, columns=[f\"C{j+1}\" for j in range(10)], index=[f\"F{10-i}\" for i in range(10)])\n",
    "display(dfValores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F10</th>\n",
       "      <td>⬅️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>0.0</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>⬅️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F9</th>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>0.0</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>⬅️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F8</th>\n",
       "      <td>⬅️</td>\n",
       "      <td>0.0</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F7</th>\n",
       "      <td>⬅️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>0.0</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F6</th>\n",
       "      <td>⬅️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5</th>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>0.0</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F4</th>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>0.0</td>\n",
       "      <td>➡️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "      <td>⬅️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "      <td>➡️</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C1   C2   C3   C4  C5   C6   C7  C8  C9 C10\n",
       "F10   ⬅️   ➡️  0.0   ⬅️  ⬅️   ⬅️   ⬅️  ➡️  ➡️  ⬅️\n",
       "F9    ⬅️   ⬅️   ⬅️   ⬅️  ⬅️   ⬅️  0.0  ⬅️  ➡️  ⬅️\n",
       "F8    ⬅️  0.0   ➡️   ➡️  ➡️   ➡️   ➡️  ➡️  ➡️  ➡️\n",
       "F7    ⬅️   ➡️   ⬅️   ⬅️  ➡️  0.0   ➡️  ➡️  ➡️  ➡️\n",
       "F6    ⬅️   ➡️   ⬅️   ➡️  ⬅️   ⬅️   ⬅️  ⬅️  ⬅️  ⬅️\n",
       "F5    ➡️   ➡️   ➡️  0.0  ⬅️   ⬅️   ⬅️  ⬅️  ⬅️  ⬅️\n",
       "F4    ➡️   ➡️  0.0   ➡️  ⬅️   ⬅️   ⬅️  ⬅️  ⬅️  ⬅️\n",
       "F3   0.0   ⬅️   ⬅️   ⬅️  ⬅️   ⬅️   ⬅️  ⬅️  ⬅️  ⬅️\n",
       "F2    ➡️   ➡️   ➡️   ➡️  ➡️   ➡️   ➡️  ➡️  ➡️  ➡️\n",
       "F1    ➡️   ➡️   ➡️   ➡️  ➡️   ➡️   ➡️  ➡️  ➡️  ➡️"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear una matriz vacía de 10x10 para la política\n",
    "politicaTablero = np.zeros((10, 10), dtype=object)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        estado = i * 10 + (j + 1 if i % 2 == 0 else 10 - j)\n",
    "        politicaTablero[9 - i, j] = piPunto3a[estado]\n",
    "\n",
    "politicaTablero = np.where(politicaTablero == -1, \"⬅️\", politicaTablero)\n",
    "politicaTablero = np.where(politicaTablero == 1, \"➡️\", politicaTablero)\n",
    "dfPolitica = pd.DataFrame(politicaTablero, columns=[f\"C{j+1}\" for j in range(10)], index=[f\"F{10-i}\" for i in range(10)])\n",
    "display(dfPolitica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **b)** Halle una política óptima usando el algoritmo de control de Montecarlo off-policy, donde la política de comportamiento es la política aleatoria. Chequee la optimalidad de esta política.\n",
    "\n",
    "Como ya tenemos los nuevos estados terminales podemos definir el **MDP** y se usa todo lo desarrollado en el **punto 3** para definir la politica optima con el algoritmo de **Monte Carlo Off Policy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado</th>\n",
       "      <th>Mejor Acción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Estado  Mejor Acción\n",
       "0        1            -1\n",
       "1        2            -1\n",
       "2        3             1\n",
       "3        4            -1\n",
       "4        5             1\n",
       "..     ...           ...\n",
       "95      96            -1\n",
       "96      97            -1\n",
       "97      98             0\n",
       "98      99            -1\n",
       "99     100            -1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejecutar Monte Carlo Off-Policy\n",
    "politicaOptima, Q = montecarloOffPolicy(1000, estados, escaleras, serpientes, probabilidades, gamma)\n",
    "dfPoliticaOptima = pd.DataFrame(list(politicaOptima.items()), columns=['Estado', 'Mejor Acción'])\n",
    "display(dfPoliticaOptima)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estado</th>\n",
       "      <th>Acción política</th>\n",
       "      <th>Acción óptima según Q</th>\n",
       "      <th>¿Es óptima?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Estado  Acción política  Acción óptima según Q  ¿Es óptima?\n",
       "0        1               -1                     -1         True\n",
       "1        2               -1                     -1         True\n",
       "2        3                1                      1         True\n",
       "3        4               -1                     -1         True\n",
       "4        5                1                      1         True\n",
       "..     ...              ...                    ...          ...\n",
       "95      96               -1                     -1         True\n",
       "96      97               -1                     -1         True\n",
       "97      98                0                     -1        False\n",
       "98      99               -1                     -1         True\n",
       "99     100               -1                     -1         True\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿La política es óptima? False\n"
     ]
    }
   ],
   "source": [
    "dfCheck, esOptima = verificarOptimalidadPolitica(politicaOptima, Q, estados)\n",
    "display(dfCheck)\n",
    "print(\"¿La política es óptima?\", esOptima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **c)** Ejecute 1000 partidas con cada una de las políticas encontradas y compare los resultados obtenidos en cuanto a porcentaje de partidas ganadas y número de pasos promedio de los episodios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_politica(politica, num_episodios):\n",
    "    partidas_ganadas = 0\n",
    "    total_pasos = 0\n",
    "\n",
    "    for _ in range(num_episodios):\n",
    "        estado = 1\n",
    "        pasos = 0\n",
    "\n",
    "        while estado not in gana and estado not in pierde:\n",
    "            accion = politica[int(estado)]\n",
    "            dado = np.random.choice(np.arange(1, 7), p=probabilidades)\n",
    "            nuevo_estado, _ = transicionRecompensaMontecarlo(estado, accion, dado, tamañoTablero, escaleras, serpientes)\n",
    "            estado = nuevo_estado\n",
    "            pasos += 1\n",
    "\n",
    "        if estado in gana:\n",
    "            partidas_ganadas += 1\n",
    "\n",
    "        total_pasos += pasos\n",
    "\n",
    "    porcentaje_ganadas = (partidas_ganadas / num_episodios) * 100\n",
    "    promedio_pasos = total_pasos / num_episodios\n",
    "\n",
    "    return porcentaje_ganadas, promedio_pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentaje_ganadas, promedio_pasos = evaluar_politica(piPunto3a, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de partidas ganadas siguiendo la politica  100.0  y cantidad de pasos promedio para lobrar la victoria 23.684  haciedo uso del algoritmo de iteracion de valor\n"
     ]
    }
   ],
   "source": [
    "print(\"Porcentaje de partidas ganadas siguiendo la politica \", porcentaje_ganadas, \" y cantidad de pasos promedio para lobrar la victoria\", \n",
    "      promedio_pasos, \" haciedo uso del algoritmo de iteracion de valor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentaje_ganadas, promedio_pasos = evaluar_politica(politicaOptima, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de partidas ganadas siguiendo la politica  99.5  y cantidad de pasos promedio para lobrar la victoria 31.877  haciedo uso del algoritmo de Monte Carlo\n"
     ]
    }
   ],
   "source": [
    "print(\"Porcentaje de partidas ganadas siguiendo la politica \", porcentaje_ganadas, \" y cantidad de pasos promedio para lobrar la victoria\", \n",
    "      promedio_pasos, \" haciedo uso del algoritmo de Monte Carlo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "- Ambos algoritmos encuentran una politica optima logrando llevar al agente a maximizar la recompenza esperada, estos cambios en las politicas se deben a que el algoritmo de iteracion de valor es determista y Monte Carlo tiene un comportamiento estocastico.\n",
    "- El algoritmo de iteracion de valor es un metodo que necesita conocer la dinamica del MDP, porque en funcion de las transiciones y recompensas actualiza los valores de los estados en las iteraciones. Por el contrario, Monte Carlo no requiere las probabilidades de las transiciones dado que para estos interactua con el entorno, en este caso el algoritmo aprende apartir de muchas muestras de episodios completos.\n",
    "- Monte Carlos requiere mas tiempo computacional dado que aprende de simulaciones interactuando con el entorno. Por el contrario, iteracion de valor converge mas rapido dependiendo del error se determine y de los situaciones donde no se tengan muchos estados o transiciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambio para hacer push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
